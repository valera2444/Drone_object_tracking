{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab321f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ab321f9",
    "outputId": "cad6c221-a3a2-4fc3-c8e3-0398a788e06e"
   },
   "outputs": [],
   "source": [
    "#Failed to build scikit-image lap\n",
    "#!pip install -r sort_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2onArRGOO4vP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2onArRGOO4vP",
    "outputId": "678551d5-264a-486f-9e9d-97be8af73f28"
   },
   "outputs": [],
   "source": [
    "#!pip install -r utils_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrJJyRkfPcp2",
   "metadata": {
    "id": "wrJJyRkfPcp2"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "STPAqNGn9LaH",
   "metadata": {
    "id": "STPAqNGn9LaH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from utils import write_metrics_to_df, write_time_to_df, replace_cuda_with_cpu, make_all_numpy,\\\n",
    " video_annot_txt_to_dataframe, motMetricsEnhancedCalculator, convert_array, usingPIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SZcAeBsPBvR5",
   "metadata": {
    "id": "SZcAeBsPBvR5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95cdb40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f0cd25",
   "metadata": {
    "id": "80f0cd25"
   },
   "outputs": [],
   "source": [
    "#path to sequeuence on local : D:\\Drone_object_tracking\\VisDrone2019-MOT-val\\sequences\\uav0000086_00000_v\n",
    "#path to sequeuence on colab /content/drive/MyDrive/VisDrone2019-MOT-val/sequences/uav0000086_00000_v\n",
    "from os import walk\n",
    "#uav0000086_00000_v\n",
    "#uav0000268_05773_v\n",
    "video_name = 'uav0000072_04488_v'\n",
    "dir_path_source_sequences = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\sequences'\n",
    "dir_path_source_annotations = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\annotations'\n",
    "dir_path = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\sequences'+video_name\n",
    "annot_path = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\annotations'+video_name+'.txt'\n",
    "\n",
    "\n",
    "#filenames = next(walk(dir_path), (None, None, []))[2]  # [] if no file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9rkVH0MAYX2v",
   "metadata": {
    "id": "9rkVH0MAYX2v"
   },
   "outputs": [],
   "source": [
    "log/resnet50-triplet-mars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3699fbd",
   "metadata": {
    "id": "c3699fbd"
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import cv2\n",
    "from time import time\n",
    "import os.path as osp\n",
    "def make_predictions(model=None, tracker=None, dir_path_sequences=None, img_size=None):\n",
    "    '''\n",
    "    input:\n",
    "    model - model for predictions. MUST return predictions in formst like YOLOv8\n",
    "    tracker - MOT technic. SORT or DeepSORT\n",
    "    dir_path_sequences - string path to video sequence('D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\sequences\\\\uav0000268_05773_v') as example\n",
    "    img_size - image size for YOLO inference\n",
    "\n",
    "    return:\n",
    "    preds - dataframe of predictions in MOT16 format\n",
    "    str_res - string with description of time characteristics of alghorithm\n",
    "    times - dataframe of time wasted for different parts of function\n",
    "    '''\n",
    "    #print(next(walk(dir_path_sequences)))\n",
    "    #print(dir_path_sequences+'/'+next(walk(dir_path_sequences)))\n",
    "    print(dir_path_sequences)\n",
    "    print(dir_path_sequences+'\\\\'+next(walk(dir_path_sequences))[2][0])\n",
    "    height, width = cv2.imread(dir_path_sequences+'\\\\'+next(walk(dir_path_sequences))[2][0]).shape[:2]\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')\n",
    "\n",
    "    try:\n",
    "        os.remove(\"video.avi\")\n",
    "    except: pass\n",
    "\n",
    "    video = cv2.VideoWriter(f'video{os.path.basename(dir_path_sequences)}.avi', fourcc, 20, (width, height))\n",
    "\n",
    "    mot_tracker = tracker\n",
    "\n",
    "    #acc = mm.MOTAccumulator(auto_id=True)\n",
    "    #annots = video_annot_txt_to_dataframe('D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\annotations\\\\uav0000086_00000_v.txt')\n",
    "    columns=['frame_number','obj_id','left_top_x','left_top_y','width','height','confidence', 'category','truncation',\n",
    "                'occlusion']\n",
    "\n",
    "    preds = pd.DataFrame(columns=columns)\n",
    "    #print(len(filenames))\n",
    "\n",
    "    avg_yolo_time = 0.\n",
    "    avg_predictor_time = 0.\n",
    "    avg_frame_time_arr= []\n",
    "    avg_yolo_time_arr= []\n",
    "    avg_predictor_time = []\n",
    "    avg_resizing_time = []\n",
    "    avg_drawing_time = []\n",
    "    avg_reading_time = []\n",
    "\n",
    "    filenames = sorted(next(walk(dir_path_sequences), (None, None, []))[2])#BUG may appear\n",
    "    #print(filenames)\n",
    "    #i = 0\n",
    "    for idx, img_relative_path in enumerate(filenames):\n",
    "\n",
    "        time_before_fps  = time()\n",
    "        path = dir_path_sequences+'\\\\'+img_relative_path\n",
    "\n",
    "        time_before_reading = time()\n",
    "        #img = cv2.imread(path)    #Using this, time after - before is NEARLY equal for 928px, for 640 still different(at the begging of small inference time is 20 ms)\n",
    "        img = usingPIL(path)\n",
    "        time_after_reading = time()\n",
    "        avg_reading_time.append((time_after_reading-time_before_reading)*1000)\n",
    "\n",
    "        time_before_resizing = time()\n",
    "\n",
    "        time_after_resizing = time()\n",
    "        avg_resizing_time.append((time_after_resizing-time_before_resizing)*1000)\n",
    "\n",
    "        time_before_YOLO = time()\n",
    "        prediction = model(img, verbose=False,imgsz=img_size)\n",
    "        time_after_YOLO = time()\n",
    "        boxes =  prediction[0].boxes.xyxy.type(torch.IntTensor).to('cuda')\n",
    "        scores = prediction[0].boxes.conf\n",
    "        classes = prediction[0].boxes.cls.type(torch.IntTensor)\n",
    "        scores = torch.unsqueeze(scores, 1)\n",
    "\n",
    "        torch_detections = torch.cat((boxes,scores), dim=1)\n",
    "        torch_detections_cpu = replace_cuda_with_cpu(torch_detections)\n",
    "        numpy_detections = make_all_numpy(torch_detections_cpu)\n",
    "\n",
    "        time_before_updating_tracker = time()\n",
    "        if type(mot_tracker) == DeepSort:\n",
    "            numpy_detections = np.concatenate((numpy_detections,np.expand_dims(classes.cpu().numpy(),axis=1) ),\n",
    "                                            axis=1)\n",
    "          #print('a')\n",
    "            result_tracker = mot_tracker.update_tracks(convert_array(numpy_detections), frame=img) # WARNING here\n",
    "          #print('b')\n",
    "            results = []\n",
    "\n",
    "            for res in result_tracker:\n",
    "                arr = res.to_tlwh().tolist()\n",
    "                arr.append(res.track_id)\n",
    "                results.append(arr)\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            result_tracker = mot_tracker.update(numpy_detections)\n",
    "            results = result_tracker\n",
    "\n",
    "        time_after_updating_tracker = time()\n",
    "\n",
    "        time_before_drawing_predictions = time()\n",
    "\n",
    "        for res in results:\n",
    "\n",
    "            x1, y1, x2, y2, obj_id = [int(a) for a  in res]\n",
    "\n",
    "\n",
    "            cv2.rectangle(img, (x1, y1),(x2, y2), color=(255,0,0), thickness=2)\n",
    "            cv2.putText(img,str(obj_id), (x1, y1), cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), thickness=2 )\n",
    "\n",
    "            single_pred = [idx+1,obj_id,x1, y1, x2-x1, y2-y1,1,1,1,1]\n",
    "            s = pd.Series(single_pred, index=columns)\n",
    "            preds = pd.concat([s.to_frame().T, preds], ignore_index=True, axis=0)\n",
    "\n",
    "        time_after_drawing_predictions = time()\n",
    "        video.write(img)  #about 30 seconds for uav0000086_00000_v\n",
    "        time_after_fps = time()\n",
    "\n",
    "        avg_drawing_time.append((time_after_drawing_predictions-time_before_drawing_predictions)*1000)\n",
    "        avg_frame_time_arr.append((time_after_fps-time_before_fps)*1000)\n",
    "        avg_yolo_time_arr.append(time_after_YOLO - time_before_YOLO)\n",
    "        avg_predictor_time.append(time_after_updating_tracker - time_before_updating_tracker)\n",
    "        #img = image_resize(img, width=width)\n",
    "\n",
    "\n",
    "\n",
    "    str_res = ''\n",
    "    str_res+=dir_path+'\\n'\n",
    "    str_res+= f'Resized to {img_size}\\n'\n",
    "    str_res+=f'image width:{width}, image height:{height}\\n'\n",
    "    str_res+=f'Image reading time ms: {sum(avg_reading_time)/len(avg_reading_time)}\\n'\n",
    "    str_res+=f'Image resizing time ms: {sum(avg_resizing_time)/len(avg_resizing_time)}\\n'\n",
    "    str_res+=f'Avarage Yolo time ms:{sum(avg_yolo_time_arr)/len(avg_yolo_time_arr) * 1000}\\n'\n",
    "    str_res+=f'Avarage predictor time ms:{sum(avg_predictor_time)/len(avg_predictor_time) * 1000}\\n'\n",
    "    str_res+=f'Drawing predictions time ms: {sum(avg_drawing_time)/len(avg_drawing_time)}\\n'\n",
    "\n",
    "    #print(len(preds))\n",
    "    times = write_time_to_df(video_name=dir_path_sequences,\n",
    "                             resized_to=img_size,\n",
    "                             source_width=width,\n",
    "                             source_height=height,\n",
    "                             avg_reading_time=sum(avg_reading_time)/len(avg_reading_time),\n",
    "                             avg_resizing_time=sum(avg_resizing_time)/len(avg_resizing_time),\n",
    "                             avg_yolo_time=sum(avg_yolo_time_arr)/len(avg_yolo_time_arr) * 1000,\n",
    "                             avg_predictor_time=sum(avg_predictor_time)/len(avg_predictor_time) * 1000,\n",
    "                             avg_drawing_time=sum(avg_drawing_time)/len(avg_drawing_time),\n",
    "                             avg_fps_time=sum(avg_frame_time_arr)/len(avg_frame_time_arr))\n",
    "\n",
    "    return preds, str_res, times\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6343bb",
   "metadata": {
    "id": "ae6343bb"
   },
   "outputs": [],
   "source": [
    "def proccess_single_video(model=None, tracker=None, dir_path_source_sequences=None, dir_path_source_annotations=None,\n",
    "                          video_name=None, img_sz=None):\n",
    "    \"\"\"\n",
    "    proccesses one video: find time and accuracy metrics on given video\n",
    "\n",
    "    input:\n",
    "    dir_path_source_sequences - '/content/drive/MyDrive/VisDrone2019-MOT-val/sequences/'\n",
    "    dir_path_source_annotations - '/content/drive/MyDrive/VisDrone2019-MOT-val/annotations/'\n",
    "    video_name - name of video for both annots and sequences\n",
    "\n",
    "    return:\n",
    "    time_df - time results dataframe\n",
    "    metrics_df - metrics results dataframe\n",
    "    \"\"\"\n",
    "    print(video_name,img_sz)\n",
    "    preds, res_str, time_df = make_predictions(model,tracker, dir_path_source_sequences+'\\\\'+video_name,img_sz)\n",
    "\n",
    "    annots = video_annot_txt_to_dataframe(f'{dir_path_source_annotations}/{video_name}.txt')\n",
    "\n",
    "    MOT, metrics_df = motMetricsEnhancedCalculator(annots.to_numpy(), preds.to_numpy() )\n",
    "\n",
    "    return time_df, metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dd0a5f",
   "metadata": {
    "id": "83dd0a5f"
   },
   "outputs": [],
   "source": [
    "def proccess_all_videos():\n",
    "    time_columns=['video_name','resized_to', 'source_width','source_height','avg_reading_time','avg_resizing_time',\n",
    "              'avg_yolo_time','avg_predictor_time','avg_drawing_time']\n",
    "    times_dataframe = pd.DataFrame(columns=time_columns)\n",
    "\n",
    "\n",
    "    metric_columns = ['num_frames', 'idf1', 'idp', 'idr', 'recall', 'precision', 'num_objects',  'mostly_tracked',\n",
    "                    'partially_tracked', 'mostly_lost', 'num_false_positives', 'num_misses', 'num_switches',\n",
    "                    'num_fragmentations', 'mota', 'motp']\n",
    "    metrics_dataframe = pd.DataFrame(columns=metric_columns)\n",
    "\n",
    "    with open('results.txt', 'w') as f:\n",
    "        for video in  os.listdir(dir_path_source_sequences):\n",
    "            for s in [640]:#[640,928]\n",
    "\n",
    "                print(video)\n",
    "                print(s)\n",
    "\n",
    "                times_df, metrics_df = proccess_single_video(model, tracker,dir_path_source_sequences,\n",
    "                                                             dir_path_source_annotations,video, s)\n",
    "\n",
    "                times_dataframe = pd.concat([times_df, times_dataframe], ignore_index=True, axis=0)\n",
    "                metrics_dataframe = pd.concat([metrics_dataframe, metrics_df], ignore_index=True, axis=0)\n",
    "\n",
    "    return times_dataframe, metrics_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8jM-HzVP5CEB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8jM-HzVP5CEB",
    "outputId": "0bc60ff3-6a92-485d-addb-b9cf6e2fe3e6"
   },
   "outputs": [],
   "source": [
    "\n",
    "#!pip install ultralytics\n",
    "#https://github.com/levan92/deep_sort_realtime/blob/master/deep_sort_realtime/embedder/embedder_pytorch.py\n",
    "#!pip install deep-sort-realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Au9uhUEq5eZ0",
   "metadata": {
    "id": "Au9uhUEq5eZ0"
   },
   "outputs": [],
   "source": [
    "#from sort import Sort    # crashes kernel\n",
    "#from deepsort.tracker import DeepSortTracker\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PLG7OcEk76pK",
   "metadata": {
    "id": "PLG7OcEk76pK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AMoE5LR-47iU",
   "metadata": {
    "id": "AMoE5LR-47iU"
   },
   "outputs": [],
   "source": [
    "# Load a pretrained model\n",
    "# Weights from https://huggingface.co/ENOT-AutoDL/yolov8s_visdrone/tree/main/enot_neural_architecture_selection_x3/weights\n",
    "\n",
    "\n",
    "model = YOLO(\"YOLOv8s(x3).pt\")\n",
    "\n",
    "model.to('cuda');\n",
    "tracker = DeepSort(max_age=20,\n",
    "                   nms_max_overlap=0.7,\n",
    "                   embedder='torchreid',\n",
    "                  embedder_wts='log/resnet50-triplet-mars')\n",
    "#tracker = Sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7dd17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df, metrics_df = proccess_all_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m8NYdhqb5z4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "m8NYdhqb5z4f",
    "outputId": "10d8b1c1-e867-4d2d-c2e1-2eb7a2812c96"
   },
   "outputs": [],
   "source": [
    "time_df, metrics_df = proccess_single_video(model=model,\n",
    "                                            tracker=tracker,\n",
    "                                            dir_path_source_sequences=dir_path_source_sequences,\n",
    "                                            dir_path_source_annotations=dir_path_source_annotations,\n",
    "                                            video_name=video_name,\n",
    "                                            img_sz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "az_rccssjbX5",
   "metadata": {
    "id": "az_rccssjbX5"
   },
   "outputs": [],
   "source": [
    "time_df['clear_fps'] = time_df['avg_reading_time'] + time_df['avg_yolo_time'] + time_df['avg_predictor_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3784d4c",
   "metadata": {
    "id": "a3784d4c"
   },
   "outputs": [],
   "source": [
    "result = pd.concat((time_df, metrics_df), axis=1, ignore_index=False)\n",
    "result.to_csv('YOLOv8_s(x3)+DeepSORT.csv', sep=';', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DiveUIKq5HDz",
   "metadata": {
    "id": "DiveUIKq5HDz"
   },
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6ad1f2",
   "metadata": {
    "id": "2d6ad1f2"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98ac7b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "id": "a98ac7b2",
    "outputId": "e9eedcb6-1cf6-48b1-d8c3-2abbd768c282"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(time_df.drop(['video_name'], axis=1).astype(np.float64).corr(), annot=True, annot_kws={\"size\": 5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39985b60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "39985b60",
    "outputId": "ac0b25a8-b1ce-4e53-e283-3506d40d9b6e"
   },
   "outputs": [],
   "source": [
    "result.sort_values('clear_fps')\\\n",
    " [['resized_to','source_width',\t'source_height','avg_reading_time','avg_yolo_time','avg_predictor_time','clear_fps']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc8dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(dir_path_source_annotations+'\\\\'+video_name+'.txt')\n",
    "print(len(f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a85c7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9601278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_videos():\n",
    "\n",
    "    image_folder = dir_path_source_sequences\n",
    "    video_folder = '\\\\videos'\n",
    "    video_names = [img for img in os.listdir(image_folder)]\n",
    "    #width,height = 10,10\n",
    "\n",
    "    for name in video_names:\n",
    "        #print(next(os.walk(image_folder+'\\\\'+name))[2][0])\n",
    "        frame = cv2.imread(os.path.join(image_folder,name,next(os.walk(image_folder+'\\\\'+name))[2][0]))\n",
    "\n",
    "        height, width, layers = frame.shape\n",
    "        print(video_folder+'\\\\'+name)\n",
    "        video = cv2.VideoWriter(\"D:\\\\Drone_object_tracking\\\\\"+video_folder+'\\\\'+name+'.avi', 0, 24, (width,height))\n",
    "\n",
    "        for img in os.listdir(image_folder+'\\\\'+name):\n",
    "            video.write(cv2.imread(os.path.join(image_folder,name,img)))\n",
    "\n",
    "        #print(name)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf86020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeb3195",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7995cbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a65b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchreid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09184018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchreid.data.datasets.video.VisDroneChilds.VisDroneChild_uav0000013_00000_v import VisDroneChild_uav0000013_00000_v\n",
    "torchreid.data.register_video_dataset('VisDroneChild_uav0000013_00000_v', VisDroneChild_uav0000013_00000_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dd5201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchreid.data.datasets.video.VisDroneChilds.VisDroneChild_uav0000013_01073_v import VisDroneChild_uav0000013_01073_v\n",
    "torchreid.data.register_video_dataset('VisDroneChild_uav0000013_01073_v', VisDroneChild_uav0000013_01073_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb83f34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datamanager = torchreid.data.VideoDataManager(\n",
    "    root='D:\\\\Drone_object_tracking\\\\reid-data\\\\VisDrone2019-MOT-train',\n",
    "    sources='VisDroneChild_uav0000013_00000_v',\n",
    "    targets = 'VisDroneChild_uav0000013_00000_v',\n",
    "    height = 100,    #resizes images to this\n",
    "    width=100,\n",
    "    batch_size_train = 18,    #how many tracklets in a batch\n",
    "    batch_size_test =18,    #how many tracklets in a batch\n",
    "    num_cams = 1,\n",
    "    seq_len = 10,    # how many frmaes in a tracklet\n",
    "    num_instances = 3,    #how many tracklets per id in a batch\n",
    "    train_sampler='CustomDatasetSampler'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1662a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23432d11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = torchreid.models.build_model(\n",
    "    name='squeezenet1_1',\n",
    "    num_classes=datamanager.num_train_pids,\n",
    "    loss='triplet',\n",
    "    pretrained=False\n",
    ")\n",
    "model = model.cuda()\n",
    "optimizer = torchreid.optim.build_optimizer(\n",
    "    model, optim='adam', lr=0.0003\n",
    ")\n",
    "scheduler = torchreid.optim.build_lr_scheduler(\n",
    "    optimizer,\n",
    "    lr_scheduler='single_step',\n",
    "    stepsize=20\n",
    ")\n",
    "engine = torchreid.engine.VideoTripletEngine(\n",
    "    datamanager, model, optimizer, margin=0.3,\n",
    "    weight_t=1, weight_x=0, scheduler=scheduler,\n",
    "    pooling_method='avg'\n",
    ")\n",
    "engine.run(\n",
    "    max_epoch=15,\n",
    "    save_dir='log/resnet50-triplet-mars',\n",
    "    print_freq=5,  #if (self.batch_idx + 1) % print_freq == 0:, where for self.batch_idx, data in enumerate(self.train_loader):\n",
    "    eval_freq=1,\n",
    "    test_only=True\n",
    "    \n",
    ")\n",
    "#loss_t - triplet loss\n",
    "#loss_x - cross entropy loss\n",
    "#validation on same as training - 100% results\n",
    "#sampler selects tracklets to batches??\n",
    "\"\"\" used like:\n",
    "self.train_loader = torch.utils.data.DataLoader(\n",
    "            trainset,\n",
    "            sampler=build_train_sampler(\n",
    "                trainset.train,\n",
    "                train_sampler,\n",
    "                batch_size=batch_size_train,\n",
    "                num_instances=num_instances,\n",
    "                num_cams=num_cams,\n",
    "                num_datasets=num_datasets\n",
    "            ),\n",
    "            ...\n",
    "        )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274e4932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cython\n",
    "if cython.compiled:\n",
    "    print(\"Yep, I'm compiled.\")\n",
    "else:\n",
    "    print(\"Just a lowly interpreted script.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b391a2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2c445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_train_root_dir = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-train\\\\'\n",
    "video_val_root_dir = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\'\n",
    "\n",
    "sequences_dir = 'sequences\\\\'\n",
    "annot_dir = 'annotations\\\\'\n",
    "\n",
    "save_root_train_dir = 'D:\\\\Drone_object_tracking\\\\reid-data\\\\VisDrone2019-MOT-train\\\\'\n",
    "save_root_val_dir = 'D:\\\\Drone_object_tracking\\\\reid-data\\\\VisDrone2019-MOT-val\\\\'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6907a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b638287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import video_annot_txt_to_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4f3097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f64d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SAVE_DFS = dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baea0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caa9ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_VisDrone_to_ReID()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d50fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c3dbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visdrone_to_df(video_root_dir, video_annot_dir, video_seq_dir):\n",
    "    \"\"\"\n",
    "    converts visdrone from txt to dataframes. Each video - one dataframe\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    dirs = os.listdir(osp.join(video_root_dir,video_seq_dir))\n",
    "    \n",
    "    for name in dirs:\n",
    "        dfs.append(video_annot_txt_to_dataframe(osp.join(video_root_dir,video_annot_dir,name+'.txt')))\n",
    "        print(f'{name} converted to df')\n",
    "    return dfs\n",
    "#dfs.append(video_annot_txt_to_dataframe(osp.join(video_train_root_dir,annot_train_dir,name+'.txt')))\n",
    "#dirs = os.listdir(osp.join(video_root_dir,sequences_train_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca44473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_from_df(dfs,video_root_dir,video_annot_dir, video_seq_dir, save_dir ):\n",
    "    \"\"\"\n",
    "    write from dataframe to file system. Data will have next form:\n",
    "    -root\n",
    "    --video1\n",
    "    ---id1\n",
    "    ----img1\n",
    "    ----img2\n",
    "    ----....\n",
    "    ---id2\n",
    "    ----img1\n",
    "    ----img2\n",
    "    --video2\n",
    "    ---id1\n",
    "    ----img1\n",
    "    ----img2\n",
    "    ---id2\n",
    "    ----img1\n",
    "    ----img2\n",
    "    ----....\n",
    "    \"\"\"\n",
    "    dirs = os.listdir(osp.join(video_root_dir,video_seq_dir))\n",
    "\n",
    "    for (name,df) in zip(dirs, dfs):#для 1го видео\n",
    "\n",
    "            frame_pathes = [osp.join(video_root_dir, video_seq_dir, name, f_n) \\\n",
    "                            for f_n in os.listdir(osp.join(video_root_dir, video_seq_dir,name))]\n",
    "\n",
    "            #print(frame_pathes)\n",
    "            for frame_id in pd.unique(df['frame_index']):\n",
    "                df_per_frame_id = df[df['frame_index'] == frame_id]\n",
    "\n",
    "                id_counter = 1    #ids unique per video\n",
    "\n",
    "                img = cv2.imread(frame_pathes[frame_id - 1])\n",
    "                #print(img)\n",
    "                for row_in_image in df_per_frame_id.iterrows():\n",
    "\n",
    "                    f_i,target_id,left_top_x,left_top_y,width,height,score,category,truncation,occlusion=list(row_in_image)[1]\n",
    "\n",
    "                    id_path = osp.join(save_dir,name,str(target_id))\n",
    "                    if not os.path.exists(id_path):\n",
    "                        os.makedirs(id_path)\n",
    "\n",
    "\n",
    "                    cv2.imwrite(osp.join(id_path,str(frame_id)+'.jpg'), img[left_top_y:left_top_y+height,\n",
    "                                                                            left_top_x:left_top_x+width])\n",
    "                    \n",
    "            print(f'{name} proccessed and written')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a228836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_train():\n",
    "    dfs = visdrone_to_df(video_train_root_dir,annot_dir,sequences_dir )\n",
    "    write_from_df(dfs,video_train_root_dir,annot_dir,sequences_dir,save_root_train_dir  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0930e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_validation():\n",
    "    dfs = visdrone_to_df(video_val_root_dir,annot_dir,sequences_dir )\n",
    "    write_from_df(dfs,video_val_root_dir,annot_dir,sequences_dir,save_root_val_dir  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e873e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_dataset(root):\n",
    "    \"\"\"\n",
    "    delete id's with less than 10 frames\n",
    "    \"\"\"\n",
    "    deleted_ids=0\n",
    "    videos_dir = os.listdir(root)\n",
    "    dic={}\n",
    "    lst = []\n",
    "    for video in videos_dir:\n",
    "        video_dir = osp.join(root,video)\n",
    "        idxs_dir = os.listdir(video_dir)\n",
    "        for idx in idxs_dir:\n",
    "            idx_dir = osp.join(video_dir,idx)\n",
    "            #if len(os.listdir(idx_dir)) < 20:\n",
    "            #    if video not in dic:\n",
    "            #        dic[video]=1\n",
    "            #    else:\n",
    "            #        dic[video]+=1\n",
    "            #    deleted_ids+=1\n",
    "                #print(idx_dir)\n",
    "            lst.append(len(os.listdir(idx_dir)))\n",
    "                \n",
    "        print(video)\n",
    "        \n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b7c320",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root = 'D:\\\\Drone_object_tracking\\\\reid-data\\\\VisDrone2019-MOT-train'\n",
    "numbers_of_frames_per_id = clear_dataset(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13639062",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(numbers_of_frames_per_id).hist(bins=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c02e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(numbers_of_frames_per_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e95dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08300c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_with_unique_idxws(src_dir, new_dir):\n",
    "    root_copy = src_dir\n",
    "    root_actual = new_dir\n",
    "    train_path, val_path = osp.join(root_copy,os.listdir(root_copy)[0]), osp.join(root_copy,os.listdir(root_copy)[1])\n",
    "    #for idx, train_seq in enumerate(os.listdir(train_path)):\n",
    "    #    new_train_seq = osp.join(root_actual,'VisDrone2019-MOT-train',train_seq)\n",
    "    #    if not os.path.exists(new_train_seq):\n",
    "    #        os.makedirs(new_train_seq)\n",
    "    #    old_train_seq_path = osp.join(train_path,train_seq )\n",
    "    #    for pid in os.listdir(old_train_seq_path):\n",
    "\n",
    "    #        old_train_pid_seq = osp.join(old_train_seq_path,pid )\n",
    "    #        new_train_pid_seq = osp.join(new_train_seq, str(idx*10000+int(pid)))\n",
    "    #        shutil.copytree(old_train_pid_seq,new_train_pid_seq, dirs_exist_ok = True )\n",
    "\n",
    "    #    print('train sequence:',train_seq)\n",
    "        \n",
    "        \n",
    "    for idx, val_seq in enumerate(os.listdir(val_path)):\n",
    "        new_val_seq = osp.join(root_actual,'VisDrone2019-MOT-val',val_seq)\n",
    "        if not os.path.exists(new_val_seq):\n",
    "            os.makedirs(new_val_seq)\n",
    "        old_val_seq_path = osp.join(val_path,val_seq )\n",
    "        for pid in os.listdir(old_val_seq_path):\n",
    "\n",
    "            old_val_pid_seq = osp.join(old_val_seq_path,pid )\n",
    "            new_val_pid_seq = osp.join(new_val_seq, str(idx*10000+int(pid)))\n",
    "            shutil.copytree(old_val_pid_seq,new_val_pid_seq, dirs_exist_ok = True )\n",
    "\n",
    "        print('validation sequence:',val_seq)\n",
    "        \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af978b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_with_unique_idxws('D:\\\\Drone_object_tracking\\\\reid-data_copy','D:\\\\Drone_object_tracking\\\\reid-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c471b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(([1,2],[3,4]))\n",
    "b=[0,1]\n",
    "a[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab32d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(([10,2],[3,4]))\n",
    "np.argsort(x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f867a495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
