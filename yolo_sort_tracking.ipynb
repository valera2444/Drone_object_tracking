{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab321f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ab321f9",
    "outputId": "cad6c221-a3a2-4fc3-c8e3-0398a788e06e"
   },
   "outputs": [],
   "source": [
    "#Failed to build scikit-image lap\n",
    "#!pip install -r sort_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2onArRGOO4vP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2onArRGOO4vP",
    "outputId": "678551d5-264a-486f-9e9d-97be8af73f28"
   },
   "outputs": [],
   "source": [
    "#!pip install -r utils_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrJJyRkfPcp2",
   "metadata": {
    "id": "wrJJyRkfPcp2"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "STPAqNGn9LaH",
   "metadata": {
    "id": "STPAqNGn9LaH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from utils import write_metrics_to_df, write_time_to_df, replace_cuda_with_cpu, make_all_numpy,\\\n",
    " video_annot_txt_to_dataframe, motMetricsEnhancedCalculator, convert_array, usingPIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f0cd25",
   "metadata": {
    "id": "80f0cd25"
   },
   "outputs": [],
   "source": [
    "#path to sequeuence on local : D:\\Drone_object_tracking\\VisDrone2019-MOT-val\\sequences\\uav0000086_00000_v\n",
    "#path to sequeuence on colab /content/drive/MyDrive/VisDrone2019-MOT-val/sequences/uav0000086_00000_v\n",
    "from os import walk\n",
    "#uav0000086_00000_v\n",
    "#uav0000268_05773_v\n",
    "video_name = 'uav0000086_00000_v'\n",
    "dir_path_source_sequences_val = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\sequences'\n",
    "dir_path_source_annotations_val = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\annotations'\n",
    "dir_path_source_sequences_train = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-train\\\\sequences'\n",
    "dir_path_source_annotations_train = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-train\\\\annotations'\n",
    "#dir_path = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\sequences'+video_name\n",
    "#annot_path = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\annotations'+video_name+'.txt'\n",
    "\n",
    "\n",
    "#filenames = next(walk(dir_path), (None, None, []))[2]  # [] if no file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3699fbd",
   "metadata": {
    "id": "c3699fbd"
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import cv2\n",
    "from time import time\n",
    "import os.path as osp\n",
    "def make_predictions(model=None, tracker=None, dir_path_sequences=None, img_size=None):\n",
    "    '''\n",
    "    also writes video in 'D:\\\\Drone_object_tracking\\\\videos_with_tracking\\\\video{os.path.basename(dir_path_sequences)}.avi'\n",
    "    input:\n",
    "    model - model for predictions. MUST return predictions in formst like YOLOv8\n",
    "    tracker - MOT technic. SORT or DeepSORT\n",
    "    dir_path_sequences - string path to video sequence('D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\sequences\\\\uav0000268_05773_v') as example\n",
    "    img_size - image size for YOLO inference\n",
    "\n",
    "    return:\n",
    "    preds - dataframe of predictions in MOT16 format\n",
    "    str_res - string with description of time characteristics of alghorithm\n",
    "    times - dataframe of time wasted for different parts of function\n",
    "    '''\n",
    "    #print(next(walk(dir_path_sequences)))\n",
    "    #print(dir_path_sequences+'/'+next(walk(dir_path_sequences)))\n",
    "    #print(dir_path_sequences)\n",
    "    #print(dir_path_sequences+'\\\\'+next(walk(dir_path_sequences))[2][0])\n",
    "    height, width = cv2.imread(dir_path_sequences+'\\\\'+next(walk(dir_path_sequences))[2][0]).shape[:2]\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')\n",
    "\n",
    "    try:\n",
    "        os.remove(\"video.avi\")\n",
    "    except: pass\n",
    "\n",
    "    video = cv2.VideoWriter(f'D:\\\\Drone_object_tracking\\\\videos_with_tracking\\\\video{os.path.basename(dir_path_sequences)}.avi', fourcc, 20, (width, height))\n",
    "\n",
    "    mot_tracker = tracker\n",
    "\n",
    "    #acc = mm.MOTAccumulator(auto_id=True)\n",
    "    #annots = video_annot_txt_to_dataframe('D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\annotations\\\\uav0000086_00000_v.txt')\n",
    "    columns=['frame_number','obj_id','left_top_x','left_top_y','width','height','confidence', 'category','truncation',\n",
    "                'occlusion']\n",
    "\n",
    "    preds = pd.DataFrame(columns=columns)\n",
    "    #print(len(filenames))\n",
    "\n",
    "    avg_yolo_time = 0.\n",
    "    avg_predictor_time = 0.\n",
    "    avg_frame_time_arr= []\n",
    "    avg_yolo_time_arr= []\n",
    "    avg_predictor_time = []\n",
    "    avg_resizing_time = []\n",
    "    avg_drawing_time = []\n",
    "    avg_reading_time = []\n",
    "\n",
    "    filenames = sorted(next(walk(dir_path_sequences), (None, None, []))[2])#BUG may appear\n",
    "    #print(filenames)\n",
    "    #i = 0\n",
    "    for idx, img_relative_path in enumerate(filenames):\n",
    "\n",
    "        time_before_fps  = time()\n",
    "        path = dir_path_sequences+'\\\\'+img_relative_path\n",
    "\n",
    "        time_before_reading = time()\n",
    "        #img = cv2.imread(path)    #Using this, time after - before is NEARLY equal for 928px, for 640 still different(at the begging of small inference time is 20 ms)\n",
    "        img = usingPIL(path)\n",
    "        time_after_reading = time()\n",
    "        avg_reading_time.append((time_after_reading-time_before_reading)*1000)\n",
    "\n",
    "        time_before_resizing = time()\n",
    "\n",
    "        time_after_resizing = time()\n",
    "        avg_resizing_time.append((time_after_resizing-time_before_resizing)*1000)\n",
    "\n",
    "        time_before_YOLO = time()\n",
    "        prediction = model(img, verbose=False,imgsz=img_size)\n",
    "        time_after_YOLO = time()\n",
    "        boxes =  prediction[0].boxes.xyxy.type(torch.IntTensor).to('cuda')\n",
    "        scores = prediction[0].boxes.conf\n",
    "        classes = prediction[0].boxes.cls.type(torch.IntTensor)\n",
    "        scores = torch.unsqueeze(scores, 1)\n",
    "\n",
    "        torch_detections = torch.cat((boxes,scores), dim=1)\n",
    "        torch_detections_cpu = replace_cuda_with_cpu(torch_detections)\n",
    "        numpy_detections = make_all_numpy(torch_detections_cpu)\n",
    "\n",
    "        time_before_updating_tracker = time()\n",
    "        \n",
    "        if type(mot_tracker) == DeepSort:\n",
    "            numpy_detections = np.concatenate((numpy_detections,np.expand_dims(classes.cpu().numpy(),axis=1) ),\n",
    "                                            axis=1)\n",
    "            \n",
    "            result_tracker = mot_tracker.update_tracks(convert_array(numpy_detections), frame=img) # WARNING here\n",
    "            results = []\n",
    "\n",
    "            for res in result_tracker:\n",
    "                if not res.is_confirmed():#state != confirmed\n",
    "                    continue\n",
    "                    \n",
    "                reses = res.to_tlwh(orig=True,orig_strict =True)\n",
    "                if reses is None:#similar to repo. Как я понял это если этому треку нет соответсвующей ground truth bbox\n",
    "                    #print('None')\n",
    "                    #print(res.track_id)\n",
    "                    continue\n",
    "                arr = reses.tolist()#this parameters enable to return only DETECTROS bboxs#orig=True,orig_strict = True\n",
    "                arr.append(res.track_id)\n",
    "                results.append(arr)\n",
    "        \n",
    "\n",
    "\n",
    "        else:\n",
    "            result_tracker = mot_tracker.update(numpy_detections)\n",
    "            results = result_tracker\n",
    "        \n",
    "            \n",
    "        time_after_updating_tracker = time()\n",
    "\n",
    "        time_before_drawing_predictions = time()\n",
    "        if idx % 100 == 0:\n",
    "            print('numpy_detections',len(numpy_detections))\n",
    "            print('results',len(results))\n",
    "        #break\n",
    "        for res in results:\n",
    "\n",
    "            x1, y1, x2, y2, obj_id = [int(a) for a  in res]\n",
    "\n",
    "\n",
    "            cv2.rectangle(img, (x1, y1),(x2, y2), color=(255,0,0), thickness=2)\n",
    "            cv2.putText(img,str(obj_id), (x1, y1), cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), thickness=2 )\n",
    "\n",
    "            single_pred = [idx+1,obj_id,x1, y1, x2-x1, y2-y1,1,1,1,1]\n",
    "            s = pd.Series(single_pred, index=columns)\n",
    "            preds = pd.concat([s.to_frame().T, preds], ignore_index=True, axis=0)\n",
    "\n",
    "        time_after_drawing_predictions = time()\n",
    "        video.write(img)  #about 30 seconds for uav0000086_00000_v\n",
    "        time_after_fps = time()\n",
    "\n",
    "        avg_drawing_time.append((time_after_drawing_predictions-time_before_drawing_predictions)*1000)\n",
    "        avg_frame_time_arr.append((time_after_fps-time_before_fps)*1000)\n",
    "        avg_yolo_time_arr.append(time_after_YOLO - time_before_YOLO)\n",
    "        avg_predictor_time.append(time_after_updating_tracker - time_before_updating_tracker)\n",
    "        #img = image_resize(img, width=width)\n",
    "\n",
    "\n",
    "\n",
    "    str_res = ''\n",
    "    str_res+=dir_path_sequences+'\\n'\n",
    "    str_res+= f'Resized to {img_size}\\n'\n",
    "    str_res+=f'image width:{width}, image height:{height}\\n'\n",
    "    str_res+=f'Image reading time ms: {sum(avg_reading_time)/len(avg_reading_time)}\\n'\n",
    "    str_res+=f'Image resizing time ms: {sum(avg_resizing_time)/len(avg_resizing_time)}\\n'\n",
    "    str_res+=f'Avarage Yolo time ms:{sum(avg_yolo_time_arr)/len(avg_yolo_time_arr) * 1000}\\n'\n",
    "    str_res+=f'Avarage predictor time ms:{sum(avg_predictor_time)/len(avg_predictor_time) * 1000}\\n'\n",
    "    str_res+=f'Drawing predictions time ms: {sum(avg_drawing_time)/len(avg_drawing_time)}\\n'\n",
    "\n",
    "    #print(len(preds))\n",
    "    times = write_time_to_df(video_name=dir_path_sequences,\n",
    "                             resized_to=img_size,\n",
    "                             source_width=width,\n",
    "                             source_height=height,\n",
    "                             avg_reading_time=sum(avg_reading_time)/len(avg_reading_time),\n",
    "                             avg_resizing_time=sum(avg_resizing_time)/len(avg_resizing_time),\n",
    "                             avg_yolo_time=sum(avg_yolo_time_arr)/len(avg_yolo_time_arr) * 1000,\n",
    "                             avg_predictor_time=sum(avg_predictor_time)/len(avg_predictor_time) * 1000,\n",
    "                             avg_drawing_time=sum(avg_drawing_time)/len(avg_drawing_time),\n",
    "                             avg_fps_time=sum(avg_frame_time_arr)/len(avg_frame_time_arr))\n",
    "\n",
    "    return preds, str_res, times\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6343bb",
   "metadata": {
    "id": "ae6343bb"
   },
   "outputs": [],
   "source": [
    "def proccess_single_video(model=None, tracker=None, dir_path_source_sequences=None, dir_path_source_annotations=None,\n",
    "                          video_name=None, img_sz=None):\n",
    "    \"\"\"\n",
    "    proccesses one video: find time and accuracy metrics on given video\n",
    "\n",
    "    input:\n",
    "    dir_path_source_sequences - '/content/drive/MyDrive/VisDrone2019-MOT-val/sequences/'\n",
    "    dir_path_source_annotations - '/content/drive/MyDrive/VisDrone2019-MOT-val/annotations/'\n",
    "    video_name - name of video for both annots and sequences\n",
    "\n",
    "    return:\n",
    "    time_df - time results dataframe\n",
    "    metrics_df - metrics results dataframe\n",
    "    \"\"\"\n",
    "    print(video_name,img_sz)\n",
    "    preds, res_str, time_df = make_predictions(model,tracker, dir_path_source_sequences+'\\\\'+video_name,img_sz)\n",
    "\n",
    "    annots = video_annot_txt_to_dataframe(f'{dir_path_source_annotations}/{video_name}.txt')\n",
    "\n",
    "    MOT, metrics_df = motMetricsEnhancedCalculator(annots.to_numpy(), preds.to_numpy() )\n",
    "\n",
    "    return time_df, metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dd0a5f",
   "metadata": {
    "id": "83dd0a5f"
   },
   "outputs": [],
   "source": [
    "def proccess_all_videos():\n",
    "    time_columns=['video_name','resized_to', 'source_width','source_height','avg_reading_time','avg_resizing_time',\n",
    "              'avg_yolo_time','avg_predictor_time','avg_drawing_time']\n",
    "    times_dataframe = pd.DataFrame(columns=time_columns)\n",
    "\n",
    "\n",
    "    metric_columns = ['num_frames', 'idf1', 'idp', 'idr', 'recall', 'precision', 'num_objects',  'mostly_tracked',\n",
    "                    'partially_tracked', 'mostly_lost', 'num_false_positives', 'num_misses', 'num_switches',\n",
    "                    'num_fragmentations', 'mota', 'motp']\n",
    "    metrics_dataframe = pd.DataFrame(columns=metric_columns)\n",
    "\n",
    "    with open('results.txt', 'w') as f:\n",
    "        for video in  os.listdir(dir_path_source_sequences_train):\n",
    "            for s in [640]:#[640,928]\n",
    "\n",
    "                print(video)\n",
    "                print(s)\n",
    "\n",
    "                times_df, metrics_df = proccess_single_video(model, tracker,dir_path_source_sequences_train,\n",
    "                                                             dir_path_source_annotations_train,video, s)\n",
    "\n",
    "                times_dataframe = pd.concat([times_df, times_dataframe], ignore_index=True, axis=0)\n",
    "                metrics_dataframe = pd.concat([metrics_dataframe, metrics_df], ignore_index=True, axis=0)\n",
    "\n",
    "    return times_dataframe, metrics_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8jM-HzVP5CEB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8jM-HzVP5CEB",
    "outputId": "0bc60ff3-6a92-485d-addb-b9cf6e2fe3e6"
   },
   "outputs": [],
   "source": [
    "\n",
    "#!pip install ultralytics\n",
    "#https://github.com/levan92/deep_sort_realtime/blob/master/deep_sort_realtime/embedder/embedder_pytorch.py\n",
    "#!pip install deep-sort-realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Au9uhUEq5eZ0",
   "metadata": {
    "id": "Au9uhUEq5eZ0"
   },
   "outputs": [],
   "source": [
    "from sort import Sort    # crashes kernel\n",
    "#from deepsort.tracker import DeepSortTracker\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PLG7OcEk76pK",
   "metadata": {
    "id": "PLG7OcEk76pK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AMoE5LR-47iU",
   "metadata": {
    "id": "AMoE5LR-47iU",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load a pretrained model\n",
    "# Weights from https://huggingface.co/ENOT-AutoDL/yolov8s_visdrone/tree/main/enot_neural_architecture_selection_x3/weights\n",
    "#!pip install sklearn.utils.linear_assignment_\n",
    "#from deep_sort_master.deep_sort import tracker\n",
    "model = YOLO(\"YOLOv8s(x3).pt\")\n",
    "\n",
    "model.to('cuda');\n",
    "tracker = DeepSort(max_age=30,\n",
    "                   #max_iou_distance=1,#WHAT IT DO??\n",
    "                   nms_max_overlap=0.88,\n",
    "                   embedder='torchreid',\n",
    "                   embedder_model_name='resnet50',\n",
    "                   embedder_wts='D:\\\\Drone_object_tracking\\\\log\\\\resnet50-triplet-mars\\\\model\\\\model.pth.tar-2')\n",
    "                   \n",
    "#tracker = Sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f656021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = 'uav0000086_00000_v'\n",
    "dir_path_source_sequences_val = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\sequences'\n",
    "dir_path_source_annotations_val = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\annotations'\n",
    "dir_path_source_sequences_train = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-train\\\\sequences'\n",
    "dir_path_source_annotations_train = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-train\\\\annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7dd17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time_df, metrics_df = proccess_all_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m8NYdhqb5z4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "m8NYdhqb5z4f",
    "outputId": "10d8b1c1-e867-4d2d-c2e1-2eb7a2812c96",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_df, metrics_df = proccess_single_video(model=model,\n",
    "                                            tracker=tracker,\n",
    "                                            dir_path_source_sequences=dir_path_source_sequences_val,\n",
    "                                            dir_path_source_annotations=dir_path_source_annotations_val,\n",
    "                                            video_name=video_name,\n",
    "                                            img_sz=640)\n",
    "\"\"\"\n",
    "DeeepSort predicts bounding boxes which yolo doesnt\n",
    "при дипсорте много перескакиъивает на соседей -\n",
    "плохой ReID может(потому что выбирается только из тех что подходят по sort, а это соседи)\n",
    "Наверное сопровождает то что утеряно на протяжении max age\n",
    "Параметры (orig=True,orig_strict =True) позволяют не выдавать то что предсказано калманом\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "az_rccssjbX5",
   "metadata": {
    "id": "az_rccssjbX5"
   },
   "outputs": [],
   "source": [
    "time_df['clear_fps'] = time_df['avg_reading_time'] + time_df['avg_yolo_time'] + time_df['avg_predictor_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e20e97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat((time_df, metrics_df), axis=1, ignore_index=False)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3784d4c",
   "metadata": {
    "id": "a3784d4c"
   },
   "outputs": [],
   "source": [
    "result = pd.concat((time_df, metrics_df), axis=1, ignore_index=False)\n",
    "result.to_csv('YOLOv8_s(x3)+DeepSORT.csv', sep=';', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DiveUIKq5HDz",
   "metadata": {
    "id": "DiveUIKq5HDz"
   },
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6ad1f2",
   "metadata": {
    "id": "2d6ad1f2"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98ac7b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "id": "a98ac7b2",
    "outputId": "e9eedcb6-1cf6-48b1-d8c3-2abbd768c282"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(time_df.drop(['video_name'], axis=1).astype(np.float64).corr(), annot=True, annot_kws={\"size\": 5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39985b60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "39985b60",
    "outputId": "ac0b25a8-b1ce-4e53-e283-3506d40d9b6e"
   },
   "outputs": [],
   "source": [
    "result.sort_values('clear_fps')\\\n",
    " [['resized_to','source_width',\t'source_height','avg_reading_time','avg_yolo_time','avg_predictor_time','clear_fps']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc8dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(dir_path_source_annotations+'\\\\'+video_name+'.txt')\n",
    "print(len(f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9601278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_videos():\n",
    "\n",
    "    image_folder = dir_path_source_sequences\n",
    "    video_folder = '\\\\videos'\n",
    "    video_names = [img for img in os.listdir(image_folder)]\n",
    "    #width,height = 10,10\n",
    "\n",
    "    for name in video_names:\n",
    "        #print(next(os.walk(image_folder+'\\\\'+name))[2][0])\n",
    "        frame = cv2.imread(os.path.join(image_folder,name,next(os.walk(image_folder+'\\\\'+name))[2][0]))\n",
    "\n",
    "        height, width, layers = frame.shape\n",
    "        print(video_folder+'\\\\'+name)\n",
    "        video = cv2.VideoWriter(\"D:\\\\Drone_object_tracking\\\\\"+video_folder+'\\\\'+name+'.avi', 0, 24, (width,height))\n",
    "\n",
    "        for img in os.listdir(image_folder+'\\\\'+name):\n",
    "            video.write(cv2.imread(os.path.join(image_folder,name,img)))\n",
    "\n",
    "        #print(name)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf86020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beeb3195",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7995cbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a65b7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Drone_object_tracking\\torchreid\\metrics\\rank.py:11: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torchreid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09184018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchreid.data.datasets.video.VisDroneChilds.VisDroneChild_uav0000013_00000_v import VisDroneChild_uav0000013_00000_v\n",
    "torchreid.data.register_video_dataset('VisDroneChild_uav0000013_00000_v', VisDroneChild_uav0000013_00000_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dd5201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchreid.data.datasets.video.VisDroneChilds.VisDroneChild_uav0000013_01073_v import VisDroneChild_uav0000013_01073_v\n",
    "torchreid.data.register_video_dataset('VisDroneChild_uav0000013_01073_v', VisDroneChild_uav0000013_01073_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adb83f34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building train transforms ...\n",
      "+ resize to 50x50\n",
      "+ random flip\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "Building test transforms ...\n",
      "+ resize to 50x50\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "=> Loading train (source) dataset\n",
      "self.video_name uav0000013_01073_v\n",
      "=> Loaded VisDroneChild_uav0000013_01073_v\n",
      "  -------------------------------------------\n",
      "  subset   | # ids | # tracklets | # cameras\n",
      "  -------------------------------------------\n",
      "  train    |    24 |          57 |         1\n",
      "  query    |     9 |           9 |         1\n",
      "  gallery  |    23 |          48 |         1\n",
      "  -------------------------------------------\n",
      "self.video_name uav0000013_00000_v\n",
      "=> Loaded VisDroneChild_uav0000013_00000_v\n",
      "  -------------------------------------------\n",
      "  subset   | # ids | # tracklets | # cameras\n",
      "  -------------------------------------------\n",
      "  train    |    56 |         543 |         1\n",
      "  query    |    42 |          90 |         1\n",
      "  gallery  |    56 |         453 |         1\n",
      "  -------------------------------------------\n",
      "=> Loading test (target) dataset\n",
      "self.video_name uav0000013_01073_v\n",
      "=> Loaded VisDroneChild_uav0000013_01073_v\n",
      "  -------------------------------------------\n",
      "  subset   | # ids | # tracklets | # cameras\n",
      "  -------------------------------------------\n",
      "  train    |    24 |          57 |         1\n",
      "  query    |     9 |           9 |         1\n",
      "  gallery  |    23 |          48 |         1\n",
      "  -------------------------------------------\n",
      "self.video_name uav0000013_01073_v\n",
      "self.video_name uav0000013_00000_v\n",
      "=> Loaded VisDroneChild_uav0000013_00000_v\n",
      "  -------------------------------------------\n",
      "  subset   | # ids | # tracklets | # cameras\n",
      "  -------------------------------------------\n",
      "  train    |    56 |         543 |         1\n",
      "  query    |    42 |          90 |         1\n",
      "  gallery  |    56 |         453 |         1\n",
      "  -------------------------------------------\n",
      "self.video_name uav0000013_00000_v\n",
      "\n",
      "\n",
      "  **************** Summary ****************\n",
      "  source             : ['VisDroneChild_uav0000013_01073_v', 'VisDroneChild_uav0000013_00000_v']\n",
      "  # source datasets  : 2\n",
      "  # source ids       : 80\n",
      "  # source tracklets : 600\n",
      "  # source cameras   : 2\n",
      "  target             : ['VisDroneChild_uav0000013_01073_v', 'VisDroneChild_uav0000013_00000_v']\n",
      "  *****************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datamanager = torchreid.data.VideoDataManager(\n",
    "    root='D:\\\\Drone_object_tracking\\\\reid-data\\\\VisDrone2019-MOT-train',\n",
    "    sources=['VisDroneChild_uav0000013_01073_v','VisDroneChild_uav0000013_00000_v'],\n",
    "    targets = ['VisDroneChild_uav0000013_01073_v','VisDroneChild_uav0000013_00000_v'],\n",
    "    height = 50,    #resizes images to this\n",
    "    width=50,\n",
    "    batch_size_train = 18,    #how many tracklets in a batch\n",
    "    batch_size_test =18,    #how many tracklets in a batch\n",
    "    seq_len = 10,    # how many frmaes in a tracklet\n",
    "    num_instances = 3,    #how many tracklets per id in a batch\n",
    "    train_sampler='CustomDatasetSampler'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1662a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "368934f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchreid.models.build_model(\n",
    "    name='resnet50',\n",
    "    num_classes=datamanager.num_train_pids,\n",
    "    loss='triplet',\n",
    "    pretrained=False\n",
    ")\n",
    "model = model.cuda()\n",
    "optimizer = torchreid.optim.build_optimizer(\n",
    "    model, optim='adam', lr=0.0003\n",
    ")\n",
    "\n",
    "scheduler = torchreid.optim.build_lr_scheduler(\n",
    "    optimizer,\n",
    "    lr_scheduler='single_step',\n",
    "    stepsize=300,\n",
    "    gamma = 1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23432d11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Start training\n",
      "epoch: [1/150][2/30]\ttime 0.344 (12.544)\tdata 0.000 (8.450)\teta 15:40:22\tloss_t 5.9782 (10.9292)\tlr 0.000300\n",
      "epoch: [1/150][4/30]\ttime 0.859 (6.710)\tdata 0.000 (4.225)\teta 8:22:47\tloss_t 6.7888 (8.5496)\tlr 0.000300\n",
      "epoch: [1/150][6/30]\ttime 0.867 (4.766)\tdata 0.000 (2.817)\teta 5:57:00\tloss_t 5.6835 (7.5054)\tlr 0.000300\n",
      "epoch: [1/150][8/30]\ttime 0.864 (3.793)\tdata 0.000 (2.113)\teta 4:44:00\tloss_t 4.4348 (6.8349)\tlr 0.000300\n",
      "epoch: [1/150][10/30]\ttime 0.875 (3.209)\tdata 0.000 (1.690)\teta 4:00:07\tloss_t 3.9520 (6.3219)\tlr 0.000300\n",
      "epoch: [1/150][12/30]\ttime 0.882 (2.821)\tdata 0.000 (1.408)\teta 3:31:01\tloss_t 3.5719 (5.8653)\tlr 0.000300\n",
      "epoch: [1/150][14/30]\ttime 0.886 (2.544)\tdata 0.000 (1.208)\teta 3:10:12\tloss_t 5.2116 (5.6425)\tlr 0.000300\n",
      "epoch: [1/150][16/30]\ttime 0.889 (2.337)\tdata 0.000 (1.057)\teta 2:54:39\tloss_t 3.7176 (5.3761)\tlr 0.000300\n",
      "epoch: [1/150][18/30]\ttime 0.875 (2.175)\tdata 0.000 (0.940)\teta 2:42:28\tloss_t 3.0938 (5.1249)\tlr 0.000300\n",
      "epoch: [1/150][20/30]\ttime 0.877 (2.046)\tdata 0.000 (0.846)\teta 2:32:47\tloss_t 3.3345 (4.9385)\tlr 0.000300\n",
      "epoch: [1/150][22/30]\ttime 0.891 (1.940)\tdata 0.000 (0.769)\teta 2:24:47\tloss_t 2.8137 (4.7660)\tlr 0.000300\n",
      "epoch: [1/150][24/30]\ttime 0.888 (1.853)\tdata 0.000 (0.705)\teta 2:18:15\tloss_t 2.9861 (4.6264)\tlr 0.000300\n",
      "epoch: [1/150][26/30]\ttime 0.900 (1.779)\tdata 0.000 (0.651)\teta 2:12:40\tloss_t 2.6344 (4.4763)\tlr 0.000300\n",
      "epoch: [1/150][28/30]\ttime 0.886 (1.716)\tdata 0.000 (0.604)\teta 2:07:54\tloss_t 2.9756 (4.3923)\tlr 0.000300\n",
      "epoch: [1/150][30/30]\ttime 0.909 (1.662)\tdata 0.000 (0.564)\teta 2:03:49\tloss_t 2.7728 (4.2899)\tlr 0.000300\n",
      "##### Evaluating VisDroneChild_uav0000013_01073_v (source) #####\n",
      "Extracting features from query set ...\n",
      "Done, obtained 9-by-2048 matrix\n",
      "Extracting features from gallery set ...\n",
      "Done, obtained 48-by-2048 matrix\n",
      "Speed: 0.0078 sec/batch\n",
      "Computing distance matrix with metric=euclidean ...\n",
      "Computing CMC and mAP ...\n",
      "eval market 1501\n",
      "Note: number of gallery samples is quite small, got 48\n",
      "** Results **\n",
      "mAP: 90.0%\n",
      "CMC curve\n",
      "Rank-1  : 87.5%\n",
      "Rank-5  : 100.0%\n",
      "Rank-10 : 100.0%\n",
      "Rank-20 : 100.0%\n",
      "##### Evaluating VisDroneChild_uav0000013_00000_v (source) #####\n",
      "Extracting features from query set ...\n",
      "Done, obtained 90-by-2048 matrix\n",
      "Extracting features from gallery set ...\n",
      "Done, obtained 453-by-2048 matrix\n",
      "Speed: 0.0110 sec/batch\n",
      "Computing distance matrix with metric=euclidean ...\n",
      "Computing CMC and mAP ...\n",
      "eval market 1501\n",
      "** Results **\n",
      "mAP: 41.3%\n",
      "CMC curve\n",
      "Rank-1  : 70.0%\n",
      "Rank-5  : 88.9%\n",
      "Rank-10 : 93.3%\n",
      "Rank-20 : 95.6%\n",
      "Checkpoint saved to \"log/resnet50-triplet-mars\\model\\model.pth.tar-1\"\n",
      "epoch: [2/150][2/30]\ttime 0.919 (10.239)\tdata 0.000 (9.482)\teta 12:42:27\tloss_t 3.2461 (2.9495)\tlr 0.000300\n",
      "epoch: [2/150][4/30]\ttime 0.875 (5.564)\tdata 0.000 (4.741)\teta 6:54:07\tloss_t 2.4089 (2.7393)\tlr 0.000300\n",
      "epoch: [2/150][6/30]\ttime 0.922 (4.009)\tdata 0.000 (3.161)\teta 4:58:16\tloss_t 2.1129 (2.6056)\tlr 0.000300\n",
      "epoch: [2/150][8/30]\ttime 0.875 (3.228)\tdata 0.000 (2.370)\teta 4:00:02\tloss_t 2.5184 (2.5631)\tlr 0.000300\n",
      "epoch: [2/150][10/30]\ttime 0.906 (2.760)\tdata 0.000 (1.896)\teta 3:25:11\tloss_t 2.2921 (2.4973)\tlr 0.000300\n",
      "epoch: [2/150][12/30]\ttime 0.859 (2.446)\tdata 0.000 (1.580)\teta 3:01:45\tloss_t 2.6174 (2.4905)\tlr 0.000300\n",
      "epoch: [2/150][14/30]\ttime 0.875 (2.222)\tdata 0.000 (1.355)\teta 2:45:00\tloss_t 1.9029 (2.4330)\tlr 0.000300\n",
      "epoch: [2/150][16/30]\ttime 0.859 (2.052)\tdata 0.000 (1.185)\teta 2:32:21\tloss_t 2.3472 (2.4145)\tlr 0.000300\n",
      "epoch: [2/150][18/30]\ttime 0.859 (1.921)\tdata 0.000 (1.054)\teta 2:22:30\tloss_t 2.2054 (2.3884)\tlr 0.000300\n",
      "epoch: [2/150][20/30]\ttime 0.884 (1.818)\tdata 0.000 (0.948)\teta 2:14:50\tloss_t 2.1798 (2.3645)\tlr 0.000300\n"
     ]
    }
   ],
   "source": [
    "\n",
    "engine = torchreid.engine.VideoTripletEngine(\n",
    "    datamanager, model, optimizer, margin=0.3,\n",
    "    weight_t=1, weight_x=0,scheduler=scheduler,\n",
    "    pooling_method='avg'\n",
    ")\n",
    "engine.run(\n",
    "    max_epoch=150,\n",
    "    save_dir='log/resnet50-triplet-mars',\n",
    "    print_freq=2,  #if (self.batch_idx + 1) % print_freq == 0:, where for self.batch_idx, data in enumerate(self.train_loader):\n",
    "    eval_freq=1,\n",
    "    #test_only=True,\n",
    "    #visrank =True\n",
    ")\n",
    "#loss_t - triplet loss\n",
    "#loss_x - cross entropy loss\n",
    "#validation on same as training - 100% results\n",
    "#sampler selects tracklets to batches??\n",
    "\"\"\" used like:\n",
    "self.train_loader = torch.utils.data.DataLoader(\n",
    "            trainset,\n",
    "            sampler=build_train_sampler(\n",
    "                trainset.train,\n",
    "                train_sampler,\n",
    "                batch_size=batch_size_train,\n",
    "                num_instances=num_instances,\n",
    "                num_cams=num_cams,\n",
    "                num_datasets=num_datasets\n",
    "            ),\n",
    "            ...\n",
    "        )\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Если вообще не учить перед валидацией - 95+\n",
    "Если хотябы одну эпоху на любом датасете будет хуже\n",
    "В QUERY и GALLERY одну и тоже может попасть\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274e4932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cython\n",
    "if cython.compiled:\n",
    "    print(\"Yep, I'm compiled.\")\n",
    "else:\n",
    "    print(\"Just a lowly interpreted script.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b391a2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2c445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_train_root_dir = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-train\\\\'\n",
    "video_val_root_dir = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\'\n",
    "\n",
    "sequences_dir = 'sequences\\\\'\n",
    "annot_dir = 'annotations\\\\'\n",
    "\n",
    "save_root_train_dir = 'D:\\\\Drone_object_tracking\\\\reid-data\\\\VisDrone2019-MOT-train\\\\'\n",
    "save_root_val_dir = 'D:\\\\Drone_object_tracking\\\\reid-data\\\\VisDrone2019-MOT-val\\\\'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6907a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b638287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import video_annot_txt_to_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4f3097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f64d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SAVE_DFS = dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baea0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caa9ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_VisDrone_to_ReID()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d50fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c3dbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visdrone_to_df(video_root_dir, video_annot_dir, video_seq_dir):\n",
    "    \"\"\"\n",
    "    converts visdrone from txt to dataframes. Each video - one dataframe\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    dirs = os.listdir(osp.join(video_root_dir,video_seq_dir))\n",
    "    \n",
    "    for name in dirs:\n",
    "        dfs.append(video_annot_txt_to_dataframe(osp.join(video_root_dir,video_annot_dir,name+'.txt')))\n",
    "        print(f'{name} converted to df')\n",
    "    return dfs\n",
    "#dfs.append(video_annot_txt_to_dataframe(osp.join(video_train_root_dir,annot_train_dir,name+'.txt')))\n",
    "#dirs = os.listdir(osp.join(video_root_dir,sequences_train_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca44473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_from_df(dfs,video_root_dir,video_annot_dir, video_seq_dir, save_dir ):\n",
    "    \"\"\"\n",
    "    write from dataframe to file system. Data will have next form:\n",
    "    -root\n",
    "    --video1\n",
    "    ---id1\n",
    "    ----img1\n",
    "    ----img2\n",
    "    ----....\n",
    "    ---id2\n",
    "    ----img1\n",
    "    ----img2\n",
    "    --video2\n",
    "    ---id1\n",
    "    ----img1\n",
    "    ----img2\n",
    "    ---id2\n",
    "    ----img1\n",
    "    ----img2\n",
    "    ----....\n",
    "    \"\"\"\n",
    "    dirs = os.listdir(osp.join(video_root_dir,video_seq_dir))\n",
    "\n",
    "    for (name,df) in zip(dirs, dfs):#для 1го видео\n",
    "\n",
    "            frame_pathes = [osp.join(video_root_dir, video_seq_dir, name, f_n) \\\n",
    "                            for f_n in os.listdir(osp.join(video_root_dir, video_seq_dir,name))]\n",
    "\n",
    "            #print(frame_pathes)\n",
    "            for frame_id in pd.unique(df['frame_index']):\n",
    "                df_per_frame_id = df[df['frame_index'] == frame_id]\n",
    "\n",
    "                id_counter = 1    #ids unique per video\n",
    "\n",
    "                img = cv2.imread(frame_pathes[frame_id - 1])\n",
    "                #print(img)\n",
    "                for row_in_image in df_per_frame_id.iterrows():\n",
    "\n",
    "                    f_i,target_id,left_top_x,left_top_y,width,height,score,category,truncation,occlusion=list(row_in_image)[1]\n",
    "\n",
    "                    id_path = osp.join(save_dir,name,str(target_id))\n",
    "                    if not os.path.exists(id_path):\n",
    "                        os.makedirs(id_path)\n",
    "\n",
    "\n",
    "                    cv2.imwrite(osp.join(id_path,str(frame_id)+'.jpg'), img[left_top_y:left_top_y+height,\n",
    "                                                                            left_top_x:left_top_x+width])\n",
    "                    \n",
    "            print(f'{name} proccessed and written')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a228836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_train():\n",
    "    dfs = visdrone_to_df(video_train_root_dir,annot_dir,sequences_dir )\n",
    "    write_from_df(dfs,video_train_root_dir,annot_dir,sequences_dir,save_root_train_dir  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0930e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_validation():\n",
    "    dfs = visdrone_to_df(video_val_root_dir,annot_dir,sequences_dir )\n",
    "    write_from_df(dfs,video_val_root_dir,annot_dir,sequences_dir,save_root_val_dir  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e873e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_dataset(root):\n",
    "    \"\"\"\n",
    "    delete id's with less than 10 frames\n",
    "    \"\"\"\n",
    "    deleted_ids=0\n",
    "    videos_dir = os.listdir(root)\n",
    "    dic={}\n",
    "    lst = []\n",
    "    for video in videos_dir:\n",
    "        video_dir = osp.join(root,video)\n",
    "        idxs_dir = os.listdir(video_dir)\n",
    "        for idx in idxs_dir:\n",
    "            idx_dir = osp.join(video_dir,idx)\n",
    "            #if len(os.listdir(idx_dir)) < 20:\n",
    "            #    if video not in dic:\n",
    "            #        dic[video]=1\n",
    "            #    else:\n",
    "            #        dic[video]+=1\n",
    "            #    deleted_ids+=1\n",
    "                #print(idx_dir)\n",
    "            lst.append(len(os.listdir(idx_dir)))\n",
    "                \n",
    "        print(video)\n",
    "        \n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b7c320",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root = 'D:\\\\Drone_object_tracking\\\\reid-data\\\\VisDrone2019-MOT-train'\n",
    "numbers_of_frames_per_id = clear_dataset(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13639062",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(numbers_of_frames_per_id).hist(bins=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c02e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(numbers_of_frames_per_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e95dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08300c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_with_unique_idxws(src_dir, new_dir, start_with_train = 0,start_with_val = 0 ):\n",
    "    root_copy = src_dir\n",
    "    root_actual = new_dir\n",
    "    train_path, val_path = osp.join(root_copy,os.listdir(root_copy)[0]), osp.join(root_copy,os.listdir(root_copy)[1])\n",
    "    #for idx, train_seq in enumerate(os.listdir(train_path)):\n",
    "    #    new_train_seq = osp.join(root_actual,'VisDrone2019-MOT-train',train_seq)\n",
    "    #    if not os.path.exists(new_train_seq):\n",
    "    #        os.makedirs(new_train_seq)\n",
    "    #    old_train_seq_path = osp.join(train_path,train_seq )\n",
    "    #    for pid in os.listdir(old_train_seq_path):\n",
    "\n",
    "    #        old_train_pid_seq = osp.join(old_train_seq_path,pid )\n",
    "    #        new_train_pid_seq = osp.join(new_train_seq, str(idx*10000+int(pid)))\n",
    "    #        shutil.copytree(old_train_pid_seq,new_train_pid_seq, dirs_exist_ok = True )\n",
    "\n",
    "    #    print('train sequence:',train_seq)\n",
    "        \n",
    "    i_val = 0\n",
    "    for idx, val_seq in enumerate(os.listdir(val_path)):\n",
    "        while i_val < start_with_val:\n",
    "            i_val += 1\n",
    "            continue\n",
    "        new_val_seq = osp.join(root_actual,'VisDrone2019-MOT-val',val_seq)\n",
    "        if not os.path.exists(new_val_seq):\n",
    "            os.makedirs(new_val_seq)\n",
    "        old_val_seq_path = osp.join(val_path,val_seq )\n",
    "        for pid in os.listdir(old_val_seq_path):\n",
    "\n",
    "            old_val_pid_seq = osp.join(old_val_seq_path,pid )\n",
    "            new_val_pid_seq = osp.join(new_val_seq, str(idx*10000+int(pid)))\n",
    "            shutil.copytree(old_val_pid_seq,new_val_pid_seq, dirs_exist_ok = True )\n",
    "\n",
    "        print('validation sequence:',val_seq)\n",
    "        \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af978b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_with_unique_idxws('D:\\\\Drone_object_tracking\\\\reid-data_copy','D:\\\\Drone_object_tracking\\\\reid-data',start_with_val = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb46ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82a0343",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pid in os.listdir('D:\\\\Drone_object_tracking\\\\reid-data\\\\VisDrone2019-MOT-val\\\\uav0000086_00000_v'):\n",
    "    full_path_pid = osp.join('D:\\\\Drone_object_tracking\\\\reid-data\\\\VisDrone2019-MOT-val\\\\uav0000086_00000_v',pid)\n",
    "    for i,f in enumerate(os.listdir(full_path_pid)):\n",
    "        if i % 5 != 0:\n",
    "            os.remove(osp.join(full_path_pid,f  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c471b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(([1,2],[3,4]))\n",
    "b=[0,1]\n",
    "a[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab32d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(([10,2],[3,4]))\n",
    "np.argsort(x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f867a495",
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c37d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class B(A):\n",
    "    def __init__(self):\n",
    "        print('b')\n",
    "        super().__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8e68bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab04ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        print(type(self))\n",
    "        self.h = 0\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b96ed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class B(A):\n",
    "    h=0\n",
    "    def __init__(self):\n",
    "        print(type(self))\n",
    "        super().__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d0d34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class C(A):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc88648",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = C()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc35e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26f2aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.__class__.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768bdf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.h = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fff8c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a21e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5969453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "for obj in gc.get_objects():\n",
    "    if isinstance(obj, some_class):\n",
    "        dome_something(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c53193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchreid.data.datasets import VideoDataset\n",
    "import gc\n",
    "for obj in gc.get_objects():\n",
    "    if isinstance(obj, VideoDataset):\n",
    "        print('a')\n",
    "        print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3857c135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
