{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a1f4312",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f80268c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Drone_object_tracking\\torchreid\\metrics\\rank.py:11: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torchreid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "996d04db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchreid.data.datasets.video.VisDroneChilds.VisDroneChild_uav0000013_00000_v import VisDroneChild_uav0000013_00000_v\n",
    "torchreid.data.register_video_dataset('VisDroneChild_uav0000013_00000_v', VisDroneChild_uav0000013_00000_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c9662cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchreid.data.datasets.video.VisDroneChilds.VisDroneChild_uav0000013_01073_v import VisDroneChild_uav0000013_01073_v\n",
    "torchreid.data.register_video_dataset('VisDroneChild_uav0000013_01073_v', VisDroneChild_uav0000013_01073_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e88f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchreid.data.datasets.video.VisDroneChilds.VisDroneChild_uav0000086_00000_v import VisDroneChild_uav0000086_00000_v\n",
    "torchreid.data.register_video_dataset('VisDroneChild_uav0000086_00000_v', VisDroneChild_uav0000086_00000_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3087e7f-fbc3-4a39-a396-9bcb239d66b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from torchreid.data.datasets.video.VisDroneChilds.VisDroneChild_uav0000137_00458_v import VisDroneChild_uav0000137_00458_v\n",
    "torchreid.data.register_video_dataset('VisDroneChild_uav0000137_00458_v', VisDroneChild_uav0000137_00458_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bdbdae5-6b98-4707-9cf1-c960ace7f3c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from torchreid.data.datasets.video.VisDroneChilds.VisDroneChild_uav0000182_00000_v import VisDroneChild_uav0000182_00000_v\n",
    "torchreid.data.register_video_dataset('VisDroneChild_uav0000182_00000_v', VisDroneChild_uav0000182_00000_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d3c64e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building train transforms ...\n",
      "+ resize to 200x100\n",
      "+ random flip\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "Building test transforms ...\n",
      "+ resize to 200x100\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "=> Loading train (source) dataset\n",
      "self.video_name uav0000182_00000_v\n",
      "=> Loaded VisDroneChild_uav0000182_00000_v\n",
      "  -------------------------------------------\n",
      "  subset   | # ids | # tracklets | # cameras\n",
      "  -------------------------------------------\n",
      "  train    |   151 |        1156 |         1\n",
      "  query    |    91 |         192 |         1\n",
      "  gallery  |   148 |         964 |         1\n",
      "  -------------------------------------------\n",
      "=> Loading test (target) dataset\n",
      "self.video_name uav0000137_00458_v\n",
      "=> Loaded VisDroneChild_uav0000137_00458_v\n",
      "  -------------------------------------------\n",
      "  subset   | # ids | # tracklets | # cameras\n",
      "  -------------------------------------------\n",
      "  train    |   176 |        1537 |         1\n",
      "  query    |   123 |         256 |         1\n",
      "  gallery  |   175 |        1281 |         1\n",
      "  -------------------------------------------\n",
      "self.video_name uav0000137_00458_v\n",
      "\n",
      "\n",
      "  **************** Summary ****************\n",
      "  source             : ['VisDroneChild_uav0000182_00000_v']\n",
      "  # source datasets  : 1\n",
      "  # source ids       : 151\n",
      "  # source tracklets : 1156\n",
      "  # source cameras   : 1\n",
      "  target             : ['VisDroneChild_uav0000137_00458_v']\n",
      "  *****************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datamanager = torchreid.data.VideoDataManager(\n",
    "    root='D:\\\\Drone_object_tracking\\\\reid-data\\\\VisDrone2019-MOT-val',\n",
    "    sources=['VisDroneChild_uav0000182_00000_v'],\n",
    "    targets = ['VisDroneChild_uav0000137_00458_v'],\n",
    "    height = 200,    #resizes images to this\n",
    "    width=100,\n",
    "    batch_size_train = 9,#how many tracklets in a batch. Small batch size may cause error because 1 id is nor enough to form tripleet loss. Batch_size >=  num_instances*3\n",
    "    batch_size_test = 9,#how many tracklets in a batch\n",
    "    seq_len = 10,    # how many frmaes in a tracklet\n",
    "    num_instances = 3, #how many tracklets per id in a batch\n",
    "    train_sampler='CustomDatasetSampler'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38e23b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchreid.models.build_model(\n",
    "    name='mobilenetv2_x1_4',\n",
    "    num_classes=datamanager.max_train_pid+1,#КОСТЫЛЬ, возможно)\n",
    "    loss='triplet',\n",
    "    pretrained=False\n",
    "    \n",
    ")\n",
    "model = model.cuda()\n",
    "optimizer = torchreid.optim.build_optimizer(\n",
    "    model, optim='adam', lr=0.0003\n",
    ")\n",
    "scheduler = torchreid.optim.build_lr_scheduler(\n",
    "    optimizer,\n",
    "    lr_scheduler='single_step',\n",
    "    stepsize=300,\n",
    "    gamma = 1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd033437",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = torchreid.engine.VideoTripletEngine(\n",
    "    datamanager, model,optimizer,margin=0.5, weight_t=1, weight_x=0,scheduler=scheduler,\n",
    "    pooling_method='avg'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61b4c901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"engine = torchreid.engine.VideoSoftmaxEngine(\\n    datamanager, model,optimizer,scheduler=scheduler,\\n    pooling_method='avg'\\n)\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"engine = torchreid.engine.VideoSoftmaxEngine(\n",
    "    datamanager, model,optimizer,scheduler=scheduler,\n",
    "    pooling_method='avg'\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d88a1991",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Start training\n",
      "epoch: [1/150][1/122]\ttime 28.170 (28.170)\tdata 22.096 (22.096)\teta 5 days, 23:11:26\tloss_t 0.7705 (0.7705)\tlr 0.000300\n",
      "epoch: [1/150][2/122]\ttime 3.199 (15.685)\tdata 0.031 (11.064)\teta 3 days, 7:43:15\tloss_t 0.9393 (0.8549)\tlr 0.000300\n",
      "epoch: [1/150][3/122]\ttime 5.579 (12.316)\tdata 0.000 (7.376)\teta 2 days, 14:35:44\tloss_t 0.6761 (0.7953)\tlr 0.000300\n",
      "epoch: [1/150][4/122]\ttime 5.879 (10.707)\tdata 0.000 (5.532)\teta 2 days, 6:24:50\tloss_t 0.3353 (0.6803)\tlr 0.000300\n",
      "epoch: [1/150][5/122]\ttime 5.774 (9.720)\tdata 0.000 (4.425)\teta 2 days, 1:23:51\tloss_t 0.9036 (0.7250)\tlr 0.000300\n",
      "epoch: [1/150][6/122]\ttime 6.146 (9.124)\tdata 0.000 (3.688)\teta 1 day, 22:22:03\tloss_t 2.0488 (0.9456)\tlr 0.000300\n",
      "epoch: [1/150][7/122]\ttime 5.959 (8.672)\tdata 0.000 (3.161)\teta 1 day, 20:04:02\tloss_t 0.6592 (0.9047)\tlr 0.000300\n",
      "epoch: [1/150][8/122]\ttime 5.930 (8.330)\tdata 0.000 (2.766)\teta 1 day, 18:19:24\tloss_t 1.8661 (1.0249)\tlr 0.000300\n",
      "epoch: [1/150][9/122]\ttime 5.940 (8.064)\tdata 0.000 (2.459)\teta 1 day, 16:58:19\tloss_t 1.4143 (1.0681)\tlr 0.000300\n",
      "epoch: [1/150][10/122]\ttime 5.966 (7.854)\tdata 0.000 (2.213)\teta 1 day, 15:54:13\tloss_t 0.8106 (1.0424)\tlr 0.000300\n",
      "epoch: [1/150][11/122]\ttime 5.989 (7.685)\tdata 0.000 (2.012)\teta 1 day, 15:02:23\tloss_t 0.9969 (1.0382)\tlr 0.000300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m engine\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m      2\u001b[0m     max_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m,\n\u001b[0;32m      3\u001b[0m     save_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog/mobilenetv2_x1_4-visdrone\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m     print_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m#if (self.batch_idx + 1) % print_freq == 0:, where for self.batch_idx, data in enumerate(self.train_loader):\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     eval_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m#start_epoch=start_epoch,\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m#test_only=True,\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m#visrank=True\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m#start_epoch=start_epoch,\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#loss_t - triplet loss\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#loss_x - cross entropy loss\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#validation on same as training - 100% results\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#sampler selects tracklets to batches??\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\" used like:\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mself.train_loader = torch.utils.data.DataLoader(\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m            trainset,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m        )\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Drone_object_tracking\\torchreid\\engine\\engine.py:192\u001b[0m, in \u001b[0;36mEngine.run\u001b[1;34m(self, save_dir, max_epoch, start_epoch, print_freq, fixbase_epoch, open_layers, start_eval, eval_freq, test_only, dist_metric, normalize_feature, visrank, visrank_topk, use_metric_cuhk03, ranks, rerank)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=> Start training\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_epoch):\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m    193\u001b[0m         print_freq\u001b[38;5;241m=\u001b[39mprint_freq,\n\u001b[0;32m    194\u001b[0m         fixbase_epoch\u001b[38;5;241m=\u001b[39mfixbase_epoch,\n\u001b[0;32m    195\u001b[0m         open_layers\u001b[38;5;241m=\u001b[39mopen_layers\n\u001b[0;32m    196\u001b[0m     )\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m start_eval \\\n\u001b[0;32m    199\u001b[0m        \u001b[38;5;129;01mand\u001b[39;00m eval_freq \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \\\n\u001b[0;32m    200\u001b[0m        \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m eval_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \\\n\u001b[0;32m    201\u001b[0m        \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_epoch:\n\u001b[0;32m    202\u001b[0m         rank1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest(\n\u001b[0;32m    203\u001b[0m             dist_metric\u001b[38;5;241m=\u001b[39mdist_metric,\n\u001b[0;32m    204\u001b[0m             normalize_feature\u001b[38;5;241m=\u001b[39mnormalize_feature,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m             ranks\u001b[38;5;241m=\u001b[39mranks\n\u001b[0;32m    210\u001b[0m         )\n",
      "File \u001b[1;32mD:\\Drone_object_tracking\\torchreid\\engine\\engine.py:252\u001b[0m, in \u001b[0;36mEngine.train\u001b[1;34m(self, print_freq, fixbase_epoch, open_layers)\u001b[0m\n\u001b[0;32m    250\u001b[0m data_time\u001b[38;5;241m.\u001b[39mupdate(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m end)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m#print('engine.py, 245', data['pid'])\u001b[39;00m\n\u001b[1;32m--> 252\u001b[0m loss_summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_backward(data)\n\u001b[0;32m    253\u001b[0m batch_time\u001b[38;5;241m.\u001b[39mupdate(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m end)\n\u001b[0;32m    254\u001b[0m losses\u001b[38;5;241m.\u001b[39mupdate(loss_summary)\n",
      "File \u001b[1;32mD:\\Drone_object_tracking\\torchreid\\engine\\video\\triplet.py:141\u001b[0m, in \u001b[0;36mVideoTripletEngine.forward_backward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    139\u001b[0m imgs, pids \u001b[38;5;241m=\u001b[39m prepare(data)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_gpu:\n\u001b[1;32m--> 141\u001b[0m     imgs \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m    142\u001b[0m     pids \u001b[38;5;241m=\u001b[39m pids\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m#print('pids',pids, 'triplet.py videdo 144')\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "engine.run(\n",
    "    max_epoch=150,\n",
    "    save_dir='log/mobilenetv2_x1_4-visdrone',\n",
    "    print_freq=10,  #if (self.batch_idx + 1) % print_freq == 0:, where for self.batch_idx, data in enumerate(self.train_loader):\n",
    "    eval_freq=1,\n",
    "    #start_epoch=start_epoch,\n",
    "    #test_only=True,\n",
    "    #visrank=True\n",
    "    #start_epoch=start_epoch,\n",
    "    \n",
    ")\n",
    "#loss_t - triplet loss\n",
    "#loss_x - cross entropy loss\n",
    "#validation on same as training - 100% results\n",
    "#sampler selects tracklets to batches??\n",
    "\"\"\" used like:\n",
    "self.train_loader = torch.utils.data.DataLoader(\n",
    "            trainset,\n",
    "            sampler=build_train_sampler(\n",
    "                trainset.train,\n",
    "                train_sampler,\n",
    "                batch_size=batch_size_train,\n",
    "                num_instances=num_instances,\n",
    "                num_cams=num_cams,\n",
    "                num_datasets=num_datasets\n",
    "            ),\n",
    "            ...\n",
    "        )\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Если вообще не учить перед валидацией - 95+\n",
    "Если хотябы одну эпоху на любом датасете будет хуже\n",
    "В QUERY и GALLERY одну и тоже может попасть\n",
    "\"\"\"\n",
    "#HARD MINE YRIPLET LOSS distAP not considered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b23da50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ad8922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
