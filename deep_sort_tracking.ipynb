{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab321f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ab321f9",
    "outputId": "cad6c221-a3a2-4fc3-c8e3-0398a788e06e"
   },
   "outputs": [],
   "source": [
    "#Failed to build scikit-image lap\n",
    "#!pip install -r sort_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2onArRGOO4vP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2onArRGOO4vP",
    "outputId": "678551d5-264a-486f-9e9d-97be8af73f28"
   },
   "outputs": [],
   "source": [
    "#!pip install -r utils_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrJJyRkfPcp2",
   "metadata": {
    "id": "wrJJyRkfPcp2"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "STPAqNGn9LaH",
   "metadata": {
    "id": "STPAqNGn9LaH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from utils import write_metrics_to_df, write_time_to_df, replace_cuda_with_cpu, make_all_numpy,\\\n",
    " video_annot_txt_to_dataframe, motMetricsEnhancedCalculator, convert_array, usingPIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f0cd25",
   "metadata": {
    "id": "80f0cd25"
   },
   "outputs": [],
   "source": [
    "#path to sequeuence on local : D:\\Drone_object_tracking\\VisDrone2019-MOT-val\\sequences\\uav0000086_00000_v\n",
    "#path to sequeuence on colab /content/drive/MyDrive/VisDrone2019-MOT-val/sequences/uav0000086_00000_v\n",
    "from os import walk\n",
    "#uav0000086_00000_v\n",
    "#uav0000268_05773_v\n",
    "video_name = 'uav0000086_00000_v'\n",
    "dir_path_source_sequences_val = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\sequences'\n",
    "dir_path_source_annotations_val = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\annotations'\n",
    "dir_path_source_sequences_train = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-train\\\\sequences'\n",
    "dir_path_source_annotations_train = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-train\\\\annotations'\n",
    "#dir_path = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\sequences'+video_name\n",
    "#annot_path = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\annotations'+video_name+'.txt'\n",
    "\n",
    "\n",
    "#filenames = next(walk(dir_path), (None, None, []))[2]  # [] if no file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3699fbd",
   "metadata": {
    "id": "c3699fbd"
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import cv2\n",
    "from time import time\n",
    "import os.path as osp\n",
    "def make_predictions(model=None, tracker=None, dir_path_sequences=None, img_size=None, NMS_iou = 1):\n",
    "    '''\n",
    "    also writes video in 'D:\\\\Drone_object_tracking\\\\videos_with_tracking\\\\video{os.path.basename(dir_path_sequences)}.avi'\n",
    "    input:\n",
    "    model - model for predictions. MUST return predictions in formst like YOLOv8\n",
    "    tracker - MOT technic. SORT or DeepSORT\n",
    "    dir_path_sequences - string path to video sequence('D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\sequences\\\\uav0000268_05773_v') as example\n",
    "    img_size - image size for YOLO inference\n",
    "    NMS_iou - parameter for YOLO NMS\n",
    "    return:\n",
    "    preds - dataframe of predictions in MOT16 format\n",
    "    str_res - string with description of time characteristics of alghorithm\n",
    "    times - dataframe of time wasted for different parts of function\n",
    "    '''\n",
    "    #print(next(walk(dir_path_sequences)))\n",
    "    #print(dir_path_sequences+'/'+next(walk(dir_path_sequences)))\n",
    "    #print(dir_path_sequences)\n",
    "    #print(dir_path_sequences+'\\\\'+next(walk(dir_path_sequences))[2][0])\n",
    "    height, width = cv2.imread(dir_path_sequences+'\\\\'+next(walk(dir_path_sequences))[2][0]).shape[:2]\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')\n",
    "\n",
    "    try:\n",
    "        os.remove(\"video.avi\")\n",
    "    except: pass\n",
    "\n",
    "    video = cv2.VideoWriter(f'D:\\\\Drone_object_tracking\\\\videos_with_tracking\\\\video{os.path.basename(dir_path_sequences)}.avi', fourcc, 20, (width, height))\n",
    "\n",
    "    mot_tracker = tracker\n",
    "\n",
    "    #acc = mm.MOTAccumulator(auto_id=True)\n",
    "    #annots = video_annot_txt_to_dataframe('D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\annotations\\\\uav0000086_00000_v.txt')\n",
    "    columns=['frame_number','obj_id','left_top_x','left_top_y','width','height','confidence', 'category','truncation',\n",
    "                'occlusion']\n",
    "\n",
    "    preds = pd.DataFrame(columns=columns)\n",
    "    #print(len(filenames))\n",
    "\n",
    "    avg_yolo_time = 0.\n",
    "    avg_predictor_time = 0.\n",
    "    avg_frame_time_arr= []\n",
    "    avg_yolo_time_arr= []\n",
    "    avg_predictor_time = []\n",
    "    avg_resizing_time = []\n",
    "    avg_drawing_time = []\n",
    "    avg_reading_time = []\n",
    "\n",
    "    filenames = sorted(next(walk(dir_path_sequences), (None, None, []))[2])#BUG may appear\n",
    "    #print(filenames)\n",
    "    #i = 0\n",
    "    for idx, img_relative_path in enumerate(filenames):\n",
    "\n",
    "        time_before_fps  = time()\n",
    "        path = dir_path_sequences+'\\\\'+img_relative_path\n",
    "\n",
    "        time_before_reading = time()\n",
    "        #img = cv2.imread(path)    #Using this, time after - before is NEARLY equal for 928px, for 640 still different(at the begging of small inference time is 20 ms)\n",
    "        img = usingPIL(path)\n",
    "        time_after_reading = time()\n",
    "        avg_reading_time.append((time_after_reading-time_before_reading)*1000)\n",
    "\n",
    "        time_before_resizing = time()\n",
    "\n",
    "        time_after_resizing = time()\n",
    "        avg_resizing_time.append((time_after_resizing-time_before_resizing)*1000)\n",
    "\n",
    "        time_before_YOLO = time()\n",
    "        prediction = model(img, verbose=False,imgsz=img_size, iou = NMS_iou, agnostic_nms=True)#INCORRECT!\n",
    "        time_after_YOLO = time()\n",
    "        boxes =  prediction[0].boxes.xyxy.type(torch.IntTensor).to('cuda')\n",
    "        scores = prediction[0].boxes.conf\n",
    "        classes = prediction[0].boxes.cls.type(torch.IntTensor)\n",
    "        scores = torch.unsqueeze(scores, 1)\n",
    "\n",
    "        torch_detections = torch.cat((boxes,scores), dim=1)\n",
    "        torch_detections_cpu = replace_cuda_with_cpu(torch_detections)\n",
    "        numpy_detections = make_all_numpy(torch_detections_cpu)\n",
    "\n",
    "        time_before_updating_tracker = time()\n",
    "        \n",
    "        if type(mot_tracker) == DeepSort:\n",
    "            numpy_detections = np.concatenate((numpy_detections,np.expand_dims(classes.cpu().numpy(),axis=1) ),\n",
    "                                            axis=1)\n",
    "            \n",
    "            result_tracker = mot_tracker.update_tracks(convert_array(numpy_detections), frame=img) # WARNING here\n",
    "            results = []\n",
    "\n",
    "            for res in result_tracker:\n",
    "                if not res.is_confirmed():#state != confirmed\n",
    "                    #print(res.state)\n",
    "                    continue\n",
    "                    \n",
    "                reses = res.to_tlwh(orig=True)#orig=True,orig_strict =True\n",
    "                if reses is None:#similar to repo. Как я понял это если этому треку нет соответсвующей ground truth bbox\n",
    "                    #print('None')\n",
    "                    #print(res.track_id)\n",
    "                    continue\n",
    "                arr = reses.tolist()#this parameters enable to return only DETECTROS bboxs#orig=True,orig_strict = True\n",
    "                arr.append(res.track_id)\n",
    "                results.append(arr)\n",
    "        \n",
    "\n",
    "\n",
    "        else:\n",
    "            result_tracker = mot_tracker.update(numpy_detections)\n",
    "            results = result_tracker\n",
    "        \n",
    "        \n",
    "        #results =numpy_detections\n",
    "        time_after_updating_tracker = time()\n",
    "\n",
    "        time_before_drawing_predictions = time()\n",
    "        if idx % 100 == 0:\n",
    "            print('numpy_detections',len(numpy_detections))\n",
    "            print('results',len(results))#This less because of tentatie\n",
    "        #break\n",
    "        for res in results:\n",
    "\n",
    "            x1, y1, x2, y2, obj_id = [int(a) for a  in res]\n",
    "\n",
    "\n",
    "            cv2.rectangle(img, (x1, y1),(x2, y2), color=(255,0,0), thickness=2)\n",
    "            cv2.putText(img,str(obj_id), (x1, y1), cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), thickness=2 )\n",
    "\n",
    "            single_pred = [idx+1,obj_id,x1, y1, x2-x1, y2-y1,1,1,1,1]\n",
    "            s = pd.Series(single_pred, index=columns)\n",
    "            preds = pd.concat([s.to_frame().T, preds], ignore_index=True, axis=0)\n",
    "\n",
    "        time_after_drawing_predictions = time()\n",
    "        video.write(img)  #about 30 seconds for uav0000086_00000_v\n",
    "        time_after_fps = time()\n",
    "\n",
    "        avg_drawing_time.append((time_after_drawing_predictions-time_before_drawing_predictions)*1000)\n",
    "        avg_frame_time_arr.append((time_after_fps-time_before_fps)*1000)\n",
    "        avg_yolo_time_arr.append(time_after_YOLO - time_before_YOLO)\n",
    "        avg_predictor_time.append(time_after_updating_tracker - time_before_updating_tracker)\n",
    "        #img = image_resize(img, width=width)\n",
    "\n",
    "\n",
    "\n",
    "    str_res = ''\n",
    "    str_res+=dir_path_sequences+'\\n'\n",
    "    str_res+= f'Resized to {img_size}\\n'\n",
    "    str_res+=f'image width:{width}, image height:{height}\\n'\n",
    "    str_res+=f'Image reading time ms: {sum(avg_reading_time)/len(avg_reading_time)}\\n'\n",
    "    str_res+=f'Image resizing time ms: {sum(avg_resizing_time)/len(avg_resizing_time)}\\n'\n",
    "    str_res+=f'Avarage Yolo time ms:{sum(avg_yolo_time_arr)/len(avg_yolo_time_arr) * 1000}\\n'\n",
    "    str_res+=f'Avarage predictor time ms:{sum(avg_predictor_time)/len(avg_predictor_time) * 1000}\\n'\n",
    "    str_res+=f'Drawing predictions time ms: {sum(avg_drawing_time)/len(avg_drawing_time)}\\n'\n",
    "\n",
    "    #print(len(preds))\n",
    "    times = write_time_to_df(video_name=dir_path_sequences,\n",
    "                             resized_to=img_size,\n",
    "                             source_width=width,\n",
    "                             source_height=height,\n",
    "                             avg_reading_time=sum(avg_reading_time)/len(avg_reading_time),\n",
    "                             avg_resizing_time=sum(avg_resizing_time)/len(avg_resizing_time),\n",
    "                             avg_yolo_time=sum(avg_yolo_time_arr)/len(avg_yolo_time_arr) * 1000,\n",
    "                             avg_predictor_time=sum(avg_predictor_time)/len(avg_predictor_time) * 1000,\n",
    "                             avg_drawing_time=sum(avg_drawing_time)/len(avg_drawing_time),\n",
    "                             avg_fps_time=sum(avg_frame_time_arr)/len(avg_frame_time_arr))\n",
    "\n",
    "    return preds, str_res, times\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6343bb",
   "metadata": {
    "id": "ae6343bb"
   },
   "outputs": [],
   "source": [
    "def proccess_single_video(model=None, tracker=None, dir_path_source_sequences=None, dir_path_source_annotations=None,\n",
    "                          video_name=None, img_sz=None,NMS_iou=1):\n",
    "    \"\"\"\n",
    "    proccesses one video: find time and accuracy metrics on given video\n",
    "\n",
    "    input:\n",
    "    dir_path_source_sequences - '/content/drive/MyDrive/VisDrone2019-MOT-val/sequences/'\n",
    "    dir_path_source_annotations - '/content/drive/MyDrive/VisDrone2019-MOT-val/annotations/'\n",
    "    video_name - name of video for both annots and sequences\n",
    "\n",
    "    return:\n",
    "    time_df - time results dataframe\n",
    "    metrics_df - metrics results dataframe\n",
    "    \"\"\"\n",
    "    print(video_name,img_sz)\n",
    "    preds, res_str, time_df = make_predictions(model,tracker, dir_path_source_sequences+'\\\\'+video_name,img_sz,NMS_iou)\n",
    "\n",
    "    annots = video_annot_txt_to_dataframe(f'{dir_path_source_annotations}/{video_name}.txt')\n",
    "\n",
    "    MOT, metrics_df = motMetricsEnhancedCalculator(annots.to_numpy(), preds.to_numpy() )\n",
    "\n",
    "    return time_df, metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dd0a5f",
   "metadata": {
    "id": "83dd0a5f"
   },
   "outputs": [],
   "source": [
    "def proccess_all_videos():\n",
    "    time_columns=['video_name','resized_to', 'source_width','source_height','avg_reading_time','avg_resizing_time',\n",
    "              'avg_yolo_time','avg_predictor_time','avg_drawing_time']\n",
    "    times_dataframe = pd.DataFrame(columns=time_columns)\n",
    "\n",
    "\n",
    "    metric_columns = ['num_frames', 'idf1', 'idp', 'idr', 'recall', 'precision', 'num_objects',  'mostly_tracked',\n",
    "                    'partially_tracked', 'mostly_lost', 'num_false_positives', 'num_misses', 'num_switches',\n",
    "                    'num_fragmentations', 'mota', 'motp']\n",
    "    metrics_dataframe = pd.DataFrame(columns=metric_columns)\n",
    "\n",
    "    with open('results.txt', 'w') as f:\n",
    "        for video in  os.listdir(dir_path_source_sequences_train):\n",
    "            for s in [640]:#[640,928]\n",
    "\n",
    "                print(video)\n",
    "                print(s)\n",
    "\n",
    "                times_df, metrics_df = proccess_single_video(model, tracker,dir_path_source_sequences_train,\n",
    "                                                             dir_path_source_annotations_train,video, s)\n",
    "\n",
    "                times_dataframe = pd.concat([times_df, times_dataframe], ignore_index=True, axis=0)\n",
    "                metrics_dataframe = pd.concat([metrics_dataframe, metrics_df], ignore_index=True, axis=0)\n",
    "\n",
    "    return times_dataframe, metrics_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8jM-HzVP5CEB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8jM-HzVP5CEB",
    "outputId": "0bc60ff3-6a92-485d-addb-b9cf6e2fe3e6"
   },
   "outputs": [],
   "source": [
    "\n",
    "#!pip install ultralytics\n",
    "#https://github.com/levan92/deep_sort_realtime/blob/master/deep_sort_realtime/embedder/embedder_pytorch.py\n",
    "#!pip install deep-sort-realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Au9uhUEq5eZ0",
   "metadata": {
    "id": "Au9uhUEq5eZ0"
   },
   "outputs": [],
   "source": [
    "from sort import Sort    # crashes kernel\n",
    "#from deepsort.tracker import DeepSortTracker\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PLG7OcEk76pK",
   "metadata": {
    "id": "PLG7OcEk76pK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AMoE5LR-47iU",
   "metadata": {
    "id": "AMoE5LR-47iU",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load a pretrained model\n",
    "# Weights from https://huggingface.co/ENOT-AutoDL/yolov8s_visdrone/tree/main/enot_neural_architecture_selection_x3/weights\n",
    "#!pip install sklearn.utils.linear_assignment_\n",
    "#from deep_sort_master.deep_sort import tracker\n",
    "model = YOLO(\"YOLOv8s(x3).pt\")\n",
    "\n",
    "model.to('cuda');\n",
    "#tracker = DeepSort(max_age=50,\n",
    "#                  #max_iou_distance=1,#WHAT IT DO??\n",
    "#                   embedder='torchreid',\n",
    "#                   embedder_model_name='osnet_ain_x0_25',\n",
    "#                   #embedder_wts = 'log\\\\osnet_ain_x0_25-triplet-visdrone\\\\model\\\\model.pth.tar-135',\n",
    "#                   gating_only_position = True\n",
    "#                   )\n",
    "                   \n",
    "tracker = Sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f656021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = 'uav0000086_00000_v'\n",
    "dir_path_source_sequences_val = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\sequences'\n",
    "dir_path_source_annotations_val = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\annotations'\n",
    "dir_path_source_sequences_train = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-train\\\\sequences'\n",
    "dir_path_source_annotations_train = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-train\\\\annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7dd17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time_df, metrics_df = proccess_all_videos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m8NYdhqb5z4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "m8NYdhqb5z4f",
    "outputId": "10d8b1c1-e867-4d2d-c2e1-2eb7a2812c96",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_df, metrics_df = proccess_single_video(model=model,\n",
    "                                            tracker=tracker,\n",
    "                                            dir_path_source_sequences=dir_path_source_sequences_val,\n",
    "                                            dir_path_source_annotations=dir_path_source_annotations_val\n",
    "                                            ,\n",
    "                                            video_name=video_name,\n",
    "                                            img_sz=640,\n",
    "                                            NMS_iou = 0.3)#этот параметр убирает тоько то что в одном классе, чтобы убирать в разных надо nms_agnostic. Он для YOLO\n",
    "\"\"\"\n",
    "DeeepSort predicts bounding boxes which yolo doesnt\n",
    "при дипсорте много перескакиъивает на соседей -\n",
    "плохой ReID может(потому что выбирается только из тех что подходят по sort, а это соседи)\n",
    "Наверное сопровождает то что утеряно на протяжении max age\n",
    "Параметры (orig=True,orig_strict =True) позволяют не выдавать то что предсказано калманом\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939794db",
   "metadata": {},
   "source": [
    "mobilenetv2_x1_4, trained on softmax, 82.8mAP, uav0000086_00000_v, max_age = 50. FP - 7818, switches - 1793,udf1 - 0.29\n",
    "resnet, ?pretrained? on imagenet, uav0000086_00000_v, max_age = 50.FP - 7815, switches - 922, idf1 - 0.29\n",
    "mobilenetv2_x1_4, not pretrained?, uav0000086_00000_v, max_age = 50. FP - 7827, switches - 965,udf1 - 0.29\n",
    "SORT, uav0000086_00000_v, FP - 4334, switches - 567,udf1 - 0.32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "az_rccssjbX5",
   "metadata": {
    "id": "az_rccssjbX5"
   },
   "outputs": [],
   "source": [
    "time_df['clear_fps'] = time_df['avg_reading_time'] + time_df['avg_yolo_time'] + time_df['avg_predictor_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e20e97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat((time_df, metrics_df), axis=1, ignore_index=False)\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3784d4c",
   "metadata": {
    "id": "a3784d4c"
   },
   "outputs": [],
   "source": [
    "result = pd.concat((time_df, metrics_df), axis=1, ignore_index=False)\n",
    "result.to_csv('YOLOv8_s(x3)+DeepSORT.csv', sep=';', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DiveUIKq5HDz",
   "metadata": {
    "id": "DiveUIKq5HDz",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
