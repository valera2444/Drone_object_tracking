{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab321f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ab321f9",
    "outputId": "cad6c221-a3a2-4fc3-c8e3-0398a788e06e"
   },
   "outputs": [],
   "source": [
    "#Failed to build scikit-image lap\n",
    "#!pip install -r sort_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2onArRGOO4vP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2onArRGOO4vP",
    "outputId": "678551d5-264a-486f-9e9d-97be8af73f28"
   },
   "outputs": [],
   "source": [
    "#!pip install -r utils_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wrJJyRkfPcp2",
   "metadata": {
    "id": "wrJJyRkfPcp2"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "STPAqNGn9LaH",
   "metadata": {
    "id": "STPAqNGn9LaH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from utils import write_metrics_to_df, write_time_to_df, replace_cuda_with_cpu, make_all_numpy,\\\n",
    " video_annot_txt_to_dataframe, motMetricsEnhancedCalculator, convert_array, usingPIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80f0cd25",
   "metadata": {
    "id": "80f0cd25"
   },
   "outputs": [],
   "source": [
    "#path to sequeuence on local : D:\\Drone_object_tracking\\VisDrone2019-MOT-val\\sequences\\uav0000086_00000_v\n",
    "#path to sequeuence on colab /content/drive/MyDrive/VisDrone2019-MOT-val/sequences/uav0000086_00000_v\n",
    "from os import walk\n",
    "#uav0000086_00000_v\n",
    "#uav0000268_05773_v\n",
    "video_name = 'uav0000086_00000_v'\n",
    "dir_path_source_sequences_val = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\sequences'\n",
    "dir_path_source_annotations_val = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\annotations'\n",
    "dir_path_source_sequences_train = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-train\\\\sequences'\n",
    "dir_path_source_annotations_train = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-train\\\\annotations'\n",
    "#dir_path = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\sequences'+video_name\n",
    "#annot_path = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\annotations'+video_name+'.txt'\n",
    "\n",
    "\n",
    "#filenames = next(walk(dir_path), (None, None, []))[2]  # [] if no file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3699fbd",
   "metadata": {
    "id": "c3699fbd"
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import cv2\n",
    "from time import time\n",
    "import os.path as osp\n",
    "def make_predictions(model=None, tracker=None, dir_path_sequences=None, img_size=None, NMS_iou = 1, agnostic_nms=True,orig=True,orig_strict =True ):\n",
    "    '''\n",
    "    also writes video in 'D:\\\\Drone_object_tracking\\\\videos_with_tracking\\\\video{os.path.basename(dir_path_sequences)}.avi'\n",
    "    input:\n",
    "    model - model for predictions. MUST return predictions in formst like YOLOv8\n",
    "    tracker - MOT technic. SORT or DeepSORT\n",
    "    dir_path_sequences - string path to video sequence('D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\sequences\\\\uav0000268_05773_v') as example\n",
    "    img_size - image size for YOLO inference\n",
    "    NMS_iou - parameter for YOLO NMS\n",
    "    return:\n",
    "    preds - dataframe of predictions in MOT16 format\n",
    "    str_res - string with description of time characteristics of alghorithm\n",
    "    times - dataframe of time wasted for different parts of function\n",
    "    '''\n",
    "    #print(next(walk(dir_path_sequences)))\n",
    "    #print(dir_path_sequences+'/'+next(walk(dir_path_sequences)))\n",
    "    #print(dir_path_sequences)\n",
    "    #print(dir_path_sequences+'\\\\'+next(walk(dir_path_sequences))[2][0])\n",
    "    height, width = cv2.imread(dir_path_sequences+'\\\\'+next(walk(dir_path_sequences))[2][0]).shape[:2]\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')\n",
    "\n",
    "    try:\n",
    "        os.remove(\"video.avi\")\n",
    "    except: pass\n",
    "\n",
    "    video = cv2.VideoWriter(f'D:\\\\Drone_object_tracking\\\\videos_with_tracking\\\\video{os.path.basename(dir_path_sequences)}.avi', fourcc, 20, (width, height))\n",
    "\n",
    "    mot_tracker = tracker\n",
    "\n",
    "    #acc = mm.MOTAccumulator(auto_id=True)\n",
    "    #annots = video_annot_txt_to_dataframe('D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\annotations\\\\uav0000086_00000_v.txt')\n",
    "    columns=['frame_number','obj_id','left_top_x','left_top_y','width','height','confidence', 'category','truncation',\n",
    "                'occlusion']\n",
    "\n",
    "    preds = pd.DataFrame(columns=columns)\n",
    "    #print(len(filenames))\n",
    "\n",
    "    avg_yolo_time = 0.\n",
    "    avg_predictor_time = 0.\n",
    "    avg_frame_time_arr= []\n",
    "    avg_yolo_time_arr= []\n",
    "    avg_predictor_time = []\n",
    "    avg_resizing_time = []\n",
    "    avg_drawing_time = []\n",
    "    avg_reading_time = []\n",
    "\n",
    "    filenames = sorted(next(walk(dir_path_sequences), (None, None, []))[2])#BUG may appear\n",
    "    #print(filenames)\n",
    "    #i = 0\n",
    "    for idx, img_relative_path in enumerate(filenames):\n",
    "\n",
    "        time_before_fps  = time()\n",
    "        path = dir_path_sequences+'\\\\'+img_relative_path\n",
    "\n",
    "        time_before_reading = time()\n",
    "        #img = cv2.imread(path)    #Using this, time after - before is NEARLY equal for 928px, for 640 still different(at the begging of small inference time is 20 ms)\n",
    "        img = usingPIL(path)\n",
    "        time_after_reading = time()\n",
    "        avg_reading_time.append((time_after_reading-time_before_reading)*1000)\n",
    "\n",
    "        time_before_resizing = time()\n",
    "\n",
    "        time_after_resizing = time()\n",
    "        avg_resizing_time.append((time_after_resizing-time_before_resizing)*1000)\n",
    "\n",
    "        time_before_YOLO = time()\n",
    "        prediction = model(img, verbose=False,imgsz=img_size, iou = NMS_iou, agnostic_nms=agnostic_nms)#INCORRECT!\n",
    "        time_after_YOLO = time()\n",
    "        boxes =  prediction[0].boxes.xyxy.type(torch.IntTensor).to('cuda')\n",
    "        scores = prediction[0].boxes.conf\n",
    "        classes = prediction[0].boxes.cls.type(torch.IntTensor)\n",
    "        scores = torch.unsqueeze(scores, 1)\n",
    "\n",
    "        torch_detections = torch.cat((boxes,scores), dim=1)\n",
    "        torch_detections_cpu = replace_cuda_with_cpu(torch_detections)\n",
    "        numpy_detections = make_all_numpy(torch_detections_cpu)\n",
    "\n",
    "        time_before_updating_tracker = time()\n",
    "        \n",
    "        if type(mot_tracker) == DeepSort:\n",
    "            numpy_detections = np.concatenate((numpy_detections,np.expand_dims(classes.cpu().numpy(),axis=1) ),\n",
    "                                            axis=1)\n",
    "            \n",
    "            result_tracker = mot_tracker.update_tracks(convert_array(numpy_detections), frame=img) # WARNING here\n",
    "            results = []\n",
    "\n",
    "            for res in result_tracker:\n",
    "                if not res.is_confirmed():#state != confirmed\n",
    "                    #print(res.state)\n",
    "                    continue\n",
    "                    \n",
    "                reses = res.to_tlwh(orig=orig,orig_strict = orig_strict)#orig=True,orig_strict =True\n",
    "                if reses is None:#similar to repo. Как я понял это если этому треку нет соответсвующей ground truth bbox\n",
    "                    #print('None')\n",
    "                    #print(res.track_id)\n",
    "                    continue\n",
    "                arr = reses.tolist()#this parameters enable to return only DETECTROS bboxs#orig=True,orig_strict = True\n",
    "                arr.append(res.track_id)\n",
    "                results.append(arr)\n",
    "        \n",
    "\n",
    "\n",
    "        else:\n",
    "            result_tracker = mot_tracker.update(numpy_detections)\n",
    "            results = result_tracker\n",
    "        \n",
    "        \n",
    "        #results =numpy_detections\n",
    "        time_after_updating_tracker = time()\n",
    "\n",
    "        time_before_drawing_predictions = time()\n",
    "        if idx % 100 == 0:\n",
    "            print('numpy_detections',len(numpy_detections))\n",
    "            print('results',len(results))#This less because of tentatie\n",
    "        #break\n",
    "        for res in results:\n",
    "\n",
    "            x1, y1, x2, y2, obj_id = [int(a) for a  in res]\n",
    "\n",
    "\n",
    "            cv2.rectangle(img, (x1, y1),(x2, y2), color=(255,0,0), thickness=2)\n",
    "            cv2.putText(img,str(obj_id), (x1, y1), cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), thickness=2 )\n",
    "\n",
    "            single_pred = [idx+1,obj_id,x1, y1, x2-x1, y2-y1,1,1,1,1]\n",
    "            s = pd.Series(single_pred, index=columns)\n",
    "            preds = pd.concat([s.to_frame().T, preds], ignore_index=True, axis=0)\n",
    "\n",
    "        time_after_drawing_predictions = time()\n",
    "        video.write(img)  #about 30 seconds for uav0000086_00000_v\n",
    "        time_after_fps = time()\n",
    "\n",
    "        avg_drawing_time.append((time_after_drawing_predictions-time_before_drawing_predictions)*1000)\n",
    "        avg_frame_time_arr.append((time_after_fps-time_before_fps)*1000)\n",
    "        avg_yolo_time_arr.append(time_after_YOLO - time_before_YOLO)\n",
    "        avg_predictor_time.append(time_after_updating_tracker - time_before_updating_tracker)\n",
    "        #img = image_resize(img, width=width)\n",
    "\n",
    "\n",
    "\n",
    "    str_res = ''\n",
    "    str_res+=dir_path_sequences+'\\n'\n",
    "    str_res+= f'Resized to {img_size}\\n'\n",
    "    str_res+=f'image width:{width}, image height:{height}\\n'\n",
    "    str_res+=f'Image reading time ms: {sum(avg_reading_time)/len(avg_reading_time)}\\n'\n",
    "    str_res+=f'Image resizing time ms: {sum(avg_resizing_time)/len(avg_resizing_time)}\\n'\n",
    "    str_res+=f'Avarage Yolo time ms:{sum(avg_yolo_time_arr)/len(avg_yolo_time_arr) * 1000}\\n'\n",
    "    str_res+=f'Avarage predictor time ms:{sum(avg_predictor_time)/len(avg_predictor_time) * 1000}\\n'\n",
    "    str_res+=f'Drawing predictions time ms: {sum(avg_drawing_time)/len(avg_drawing_time)}\\n'\n",
    "\n",
    "    #print(len(preds))\n",
    "    times = write_time_to_df(video_name=dir_path_sequences,\n",
    "                             resized_to=img_size,\n",
    "                             source_width=width,\n",
    "                             source_height=height,\n",
    "                             avg_reading_time=sum(avg_reading_time)/len(avg_reading_time),\n",
    "                             avg_resizing_time=sum(avg_resizing_time)/len(avg_resizing_time),\n",
    "                             avg_yolo_time=sum(avg_yolo_time_arr)/len(avg_yolo_time_arr) * 1000,\n",
    "                             avg_predictor_time=sum(avg_predictor_time)/len(avg_predictor_time) * 1000,\n",
    "                             avg_drawing_time=sum(avg_drawing_time)/len(avg_drawing_time),\n",
    "                             avg_fps_time=sum(avg_frame_time_arr)/len(avg_frame_time_arr))\n",
    "\n",
    "    return preds, str_res, times\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae6343bb",
   "metadata": {
    "id": "ae6343bb"
   },
   "outputs": [],
   "source": [
    "def proccess_single_video(model=None, tracker=None, dir_path_source_sequences=None, dir_path_source_annotations=None,\n",
    "                          video_name=None, img_sz=None,NMS_iou=0.7, agnostic_nms=True,orig=True,orig_strict =True):\n",
    "    \"\"\"\n",
    "    proccesses one video: find time and accuracy metrics on given video\n",
    "\n",
    "    input:\n",
    "    dir_path_source_sequences - '/content/drive/MyDrive/VisDrone2019-MOT-val/sequences/'\n",
    "    dir_path_source_annotations - '/content/drive/MyDrive/VisDrone2019-MOT-val/annotations/'\n",
    "    video_name - name of video for both annots and sequences\n",
    "\n",
    "    return:\n",
    "    time_df - time results dataframe\n",
    "    metrics_df - metrics results dataframe\n",
    "    \"\"\"\n",
    "    print(video_name,img_sz)\n",
    "    preds, res_str, time_df = make_predictions(model,\n",
    "                                               tracker,\n",
    "                                               dir_path_source_sequences+'\\\\'+video_name,\n",
    "                                               img_size=img_sz,\n",
    "                                               NMS_iou=NMS_iou,\n",
    "                                               agnostic_nms=agnostic_nms,\n",
    "                                               orig=orig,\n",
    "                                               orig_strict=orig_strict\n",
    "                                              )\n",
    "\n",
    "    annots = video_annot_txt_to_dataframe(f'{dir_path_source_annotations}/{video_name}.txt')\n",
    "\n",
    "    MOT, metrics_df = motMetricsEnhancedCalculator(annots.to_numpy(), preds.to_numpy() )\n",
    "\n",
    "    return time_df, metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83dd0a5f",
   "metadata": {
    "id": "83dd0a5f"
   },
   "outputs": [],
   "source": [
    "def proccess_all_videos():\n",
    "    time_columns=['video_name','resized_to', 'source_width','source_height','avg_reading_time','avg_resizing_time',\n",
    "              'avg_yolo_time','avg_predictor_time','avg_drawing_time']\n",
    "    times_dataframe = pd.DataFrame(columns=time_columns)\n",
    "\n",
    "\n",
    "    metric_columns = ['num_frames', 'idf1', 'idp', 'idr', 'recall', 'precision', 'num_objects',  'mostly_tracked',\n",
    "                    'partially_tracked', 'mostly_lost', 'num_false_positives', 'num_misses', 'num_switches',\n",
    "                    'num_fragmentations', 'mota', 'motp']\n",
    "    metrics_dataframe = pd.DataFrame(columns=metric_columns)\n",
    "\n",
    "    with open('results.txt', 'w') as f:\n",
    "        for video in  os.listdir(dir_path_source_sequences_train):\n",
    "            for s in [640]:#[640,928]\n",
    "\n",
    "                print(video)\n",
    "                print(s)\n",
    "\n",
    "                times_df, metrics_df = proccess_single_video(model, tracker,dir_path_source_sequences_train,\n",
    "                                                             dir_path_source_annotations_train,video, s)\n",
    "\n",
    "                times_dataframe = pd.concat([times_df, times_dataframe], ignore_index=True, axis=0)\n",
    "                metrics_dataframe = pd.concat([metrics_dataframe, metrics_df], ignore_index=True, axis=0)\n",
    "\n",
    "    return times_dataframe, metrics_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8jM-HzVP5CEB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8jM-HzVP5CEB",
    "outputId": "0bc60ff3-6a92-485d-addb-b9cf6e2fe3e6"
   },
   "outputs": [],
   "source": [
    "\n",
    "#!pip install ultralytics\n",
    "#https://github.com/levan92/deep_sort_realtime/blob/master/deep_sort_realtime/embedder/embedder_pytorch.py\n",
    "#!pip install deep-sort-realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "Au9uhUEq5eZ0",
   "metadata": {
    "id": "Au9uhUEq5eZ0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "from sort import Sort    # crashes kernel\n",
    "#from deepsort.tracker import DeepSortTracker\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "PLG7OcEk76pK",
   "metadata": {
    "id": "PLG7OcEk76pK"
   },
   "outputs": [],
   "source": [
    "embedder_wts = 'log\\\\mobilenetv2_x1_4-visdrone_start_21_02_22h_20m\\\\model\\\\model.pth.tar-34'\n",
    "gating_only_position = True\n",
    "max_age = 50\n",
    "max_cosine_distance = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "AMoE5LR-47iU",
   "metadata": {
    "id": "AMoE5LR-47iU",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Drone_object_tracking\\torchreid\\metrics\\rank.py:11: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: mobilenetv2_x1_4\n",
      "- params: 4,291,604\n",
      "- flops: 381,847,424\n",
      "Successfully loaded pretrained weights from \"log\\mobilenetv2_x1_4-visdrone_start_21_02_22h_20m\\model\\model.pth.tar-34\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n"
     ]
    }
   ],
   "source": [
    "# Load a pretrained model\n",
    "# Weights from https://huggingface.co/ENOT-AutoDL/yolov8s_visdrone/tree/main/enot_neural_architecture_selection_x3/weights\n",
    "#!pip install sklearn.utils.linear_assignment_\n",
    "#from deep_sort_master.deep_sort import tracker\n",
    "model = YOLO(\"YOLOv8s(x3).pt\")\n",
    "\n",
    "model.to('cuda');\n",
    "tracker = DeepSort(max_age=max_age,\n",
    "                  #max_iou_distance=1,#WHAT IT DO??\n",
    "                   embedder='torchreid',\n",
    "                   embedder_model_name='mobilenetv2_x1_4',\n",
    "                   embedder_wts = embedder_wts,\n",
    "                   gating_only_position = gating_only_position,\n",
    "                   max_cosine_distance = max_cosine_distance\n",
    "                   )\n",
    "                   \n",
    "#tracker = Sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f656021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video_name = 'uav0000137_00458_v'\n",
    "dir_path_source_sequences_val = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\sequences'\n",
    "dir_path_source_annotations_val = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-val\\\\annotations'\n",
    "dir_path_source_sequences_train = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-train\\\\sequences'\n",
    "dir_path_source_annotations_train = 'D:\\\\Drone_object_tracking\\\\VisDrone2019-MOT-train\\\\annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a7dd17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NMS_iou = 0.3\n",
    "agnostic_nms=True\n",
    "orig=True\n",
    "orig_strict = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m8NYdhqb5z4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "m8NYdhqb5z4f",
    "outputId": "10d8b1c1-e867-4d2d-c2e1-2eb7a2812c96",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uav0000137_00458_v 640\n",
      "numpy_detections 71\n",
      "results 56\n"
     ]
    }
   ],
   "source": [
    "time_df, metrics_df = proccess_single_video(model=model,\n",
    "                                            tracker=tracker,\n",
    "                                            dir_path_source_sequences=dir_path_source_sequences_val,\n",
    "                                            dir_path_source_annotations=dir_path_source_annotations_val,\n",
    "                                            video_name=video_name,\n",
    "                                            img_sz=640,\n",
    "                                            NMS_iou = NMS_iou,\n",
    "                                            agnostic_nms=agnostic_nms,\n",
    "                                            orig=orig,\n",
    "                                            orig_strict =orig_strict)#этот параметр убирает тоько то что в одном классе, чтобы убирать в разных надо nms_agnostic. Он для YOLO\n",
    "\"\"\"\n",
    "DeeepSort predicts bounding boxes which yolo doesnt\n",
    "при дипсорте много перескакиъивает на соседей -\n",
    "плохой ReID может(потому что выбирается только из тех что подходят по sort, а это соседи)\n",
    "Наверное сопровождает то что утеряно на протяжении max age\n",
    "Параметры (orig=True,orig_strict =True) позволяют не выдавать то что предсказано калманом\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009a4870-eb2d-4d73-a9c5-b306b82d112d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4827030b-3f0a-44ec-bce1-dc921803a8b1",
   "metadata": {
    "id": "az_rccssjbX5",
    "tags": []
   },
   "source": [
    "time_df['clear_fps'] = time_df['avg_reading_time'] + time_df['avg_yolo_time'] + time_df['avg_predictor_time']\n",
    "result = pd.concat((time_df, metrics_df), axis=1, ignore_index=False)\n",
    "result = pd.concat((time_df, metrics_df), axis=1, ignore_index=False)\n",
    "result.to_csv('YOLOv8_s(x3)+DeepSORT.csv', sep=';', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "DiveUIKq5HDz",
   "metadata": {
    "id": "DiveUIKq5HDz",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_frames</th>\n",
       "      <th>idf1</th>\n",
       "      <th>idp</th>\n",
       "      <th>idr</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>num_objects</th>\n",
       "      <th>mostly_tracked</th>\n",
       "      <th>partially_tracked</th>\n",
       "      <th>mostly_lost</th>\n",
       "      <th>num_false_positives</th>\n",
       "      <th>num_misses</th>\n",
       "      <th>num_switches</th>\n",
       "      <th>num_fragmentations</th>\n",
       "      <th>mota</th>\n",
       "      <th>motp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>233.0</td>\n",
       "      <td>0.325161</td>\n",
       "      <td>0.314363</td>\n",
       "      <td>0.336727</td>\n",
       "      <td>0.522351</td>\n",
       "      <td>0.48766</td>\n",
       "      <td>24361.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>13369.0</td>\n",
       "      <td>11636.0</td>\n",
       "      <td>795.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>-0.05907</td>\n",
       "      <td>0.263924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_frames      idf1       idp       idr    recall  precision  num_objects  \\\n",
       "0       233.0  0.325161  0.314363  0.336727  0.522351    0.48766      24361.0   \n",
       "\n",
       "   mostly_tracked  partially_tracked  mostly_lost  num_false_positives  \\\n",
       "0            42.0               98.0         44.0              13369.0   \n",
       "\n",
       "   num_misses  num_switches  num_fragmentations     mota      motp  \n",
       "0     11636.0         795.0              1429.0 -0.05907  0.263924  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcea15dc-b7fe-4e12-944b-900cf3ca02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {'method':type(tracker),\n",
    "      'max_age':None if type(tracker) == Sort else max_age,\n",
    "      'embedder_wts':None if type(tracker) == Sort else embedder_wts,\n",
    "      'gating_only_position':None if type(tracker) == Sort else gating_only_position,\n",
    "      'orig_strict':orig_strict,\n",
    "      'video_name':video_name,\n",
    "      'NMS_YOLO':NMS_iou,\n",
    "      'Class_agnostic':agnostic_nms,\n",
    "      'idf1':metrics_df['idf1'],\n",
    "      'num_false_positives':['num_false_positives'],\n",
    "      'num_misses':metrics_df['num_misses'],\n",
    "      'num_switches':metrics_df['num_switches'],\n",
    "      'num_framentations':metrics_df['num_fragmentations'],\n",
    "      'mota':metrics_df['mota'],\n",
    "      'max_cosine_distance' : None if type(tracker) == Sort else max_cosine_distance,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29b9942e-fbf5-45f3-b97e-417be2061941",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              method  max_age  \\\n",
      "0  <class 'deep_sort_realtime.deepsort_tracker.De...       50   \n",
      "\n",
      "                                        embedder_wts  gating_only_position  \\\n",
      "0  log\\mobilenetv2_x1_4-visdrone_start_21_02_22h_...                  True   \n",
      "\n",
      "   orig_strict          video_name  NMS_YOLO  Class_agnostic      idf1  \\\n",
      "0        False  uav0000137_00458_v       0.3            True  0.325161   \n",
      "\n",
      "   num_false_positives  num_misses  num_switches  num_framentations     mota  \\\n",
      "0  num_false_positives     11636.0         795.0             1429.0 -0.05907   \n",
      "\n",
      "   max_cosine_distance  \n",
      "0                  0.1  \n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2cd9365-a424-48e2-ac4f-95728e69b028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df.to_csv('temp_results.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ede7cfdb-afad-4b99-971c-e97a4159776c",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'temp_results.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp_results.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:3720\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3709\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3711\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3712\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3713\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3717\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3718\u001b[0m )\n\u001b[1;32m-> 3720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3721\u001b[0m     path_or_buf,\n\u001b[0;32m   3722\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3723\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3724\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3725\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3726\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3727\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3728\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3729\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3730\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3731\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3732\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3733\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3734\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3735\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3736\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3737\u001b[0m )\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1168\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1171\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1172\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1188\u001b[0m )\n\u001b[1;32m-> 1189\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1192\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    244\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    245\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    246\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    247\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    248\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'temp_results.csv'"
     ]
    }
   ],
   "source": [
    "df.to_csv('temp_results.csv', mode='a', header=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9aa39f-fac2-471b-ba69-b46dc9fb6585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
